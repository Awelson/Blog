{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>to my personal website. This is where I will try to document whatever I've learned / found interesting across various subjects. This website is split into sections accordingly based on these subjects. You may click the links below to navigate to each section and check them out. Alternatively you may use the nav-bar to the left.</p>"},{"location":"#-tigm-today-in-good-music","title":"- TIGM (Today in Good Music)","text":""},{"location":"#-japanese-section","title":"- Japanese Section \ud83d\uddfe","text":""},{"location":"#-anime-stuff","title":"- Anime Stuff","text":""},{"location":"#-video-games","title":"- Video Games","text":""},{"location":"#-youtube","title":"- YouTube","text":""},{"location":"#-chess","title":"- Chess","text":""},{"location":"#-maths","title":"- Maths","text":""},{"location":"#-science","title":"- Science","text":""},{"location":"#-cool-artworks","title":"- Cool artworks","text":"<p>... and more to come as my interests grow</p>"},{"location":"Anime/","title":"Anime Stuff","text":"<ul> <li>Anime log</li> </ul>"},{"location":"Anime/Anime%20log/","title":"What anime am I watching now?","text":"<p>I will start logging and scoring the seasonal anime I have watched (starting from Winter 2022) so that I can better keep track of things. The scoring system is as follows : </p> <p>This is an out of 8, though practically speaking 7 point scoring system. You can thank Frieren for raising the ceiling of my standards. It is the only 8 point-scoring anime in the list as of now, and probably will be for the forseeable future. Anyways, you can see below what each score means; this is based on my reaction after finishing the show. </p> <ul> <li>1 : Hate it, give me my time back</li> <li>2 : Forgettable</li> <li>3 : Meh, alright I guess</li> <li>4 : Huh, that was quite fun to watch</li> <li>5 : * gets sad when its over</li> <li>6 : * freaks out when its over</li> <li>7 : MASTERPIECE</li> <li>8 : Uh, its Frieren..</li> </ul>"},{"location":"Anime/Anime%20log/2022/","title":"2022 Anime","text":""},{"location":"Anime/Anime%20log/2022/#winter","title":"Winter","text":""},{"location":"Anime/Anime%20log/2022/Fall/","title":"Fall 2022","text":""},{"location":"Anime/Anime%20log/2022/Spring/","title":"Spring 2022","text":""},{"location":"Anime/Anime%20log/2022/Summer/","title":"Summer 2022","text":""},{"location":"Anime/Anime%20log/2022/Winter/","title":"Winter 2022","text":""},{"location":"Anime/Anime%20log/2023/","title":"2023 Anime","text":""},{"location":"Anime/Anime%20log/2023/#winter","title":"Winter","text":""},{"location":"Anime/Anime%20log/2023/Fall/","title":"Fall 2023","text":""},{"location":"Anime/Anime%20log/2023/Fall/#completed","title":"Completed","text":""},{"location":"Anime/Anime%20log/2023/Fall/#sousou-no-frieren","title":"Sousou no Frieren","text":"<p>Score : 8/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#spy-x-family-s2","title":"Spy x Family (S2)","text":"<p>Score : 6/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#kusuriya-no-hitorigoto","title":"Kusuriya no hitorigoto","text":"<p>Score : 7/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#kage-no-jitsuryokusha-s2","title":"Kage no Jitsuryokusha (S2)","text":"<p>Score : 4/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#shangri-la-frontier","title":"Shangri-La Frontier","text":"<p>Score : 4/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#undead-unluck","title":"Undead Unluck","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#tokyo-revengers-tenjiku-hen","title":"Tokyo Revengers: Tenjiku-hen","text":"<p>Score : 3/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#hamtesu-no-oukoku","title":"Hamtesu no Oukoku","text":"<p>Score : 1/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#ragna-crimson","title":"Ragna Crimson","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#kamonohashi-ron","title":"Kamonohashi Ron","text":"<p>Score : 4/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#dead-mount-death-play-s2","title":"Dead Mount Death Play (S2)","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#watashi-no-oshi-wa-akuyaku-reijou","title":"Watashi no Oshi wa Akuyaku Reijou","text":"<p>Score : 4/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#mahoutsukai-no-yome-s3","title":"Mahoutsukai no Yome (S3)","text":"<p>Score : 6/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#migi-to-dali","title":"Migi to Dali","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#under-ninja","title":"Under Ninja","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#overtake","title":"Overtake!","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#yuzuki-san-chi-no-yonkyoudai","title":"Yuzuki-san Chi no Yonkyoudai","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#atarashii-joushi-wa-do-tennen","title":"Atarashii JOushi wa Do Tennen","text":"<p>Score : 5/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#dog-signal","title":"Dog Signal","text":"<p>Score : 4/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#pluto","title":"Pluto","text":"<p>Score : 6/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#dropped","title":"Dropped","text":""},{"location":"Anime/Anime%20log/2023/Fall/#tate-no-yuusha-s3","title":"Tate no Yuusha (S3)","text":"<p>Score : 2/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#boushoku-no-berserk","title":"Boushoku no Berserk","text":"<p>Score : 2/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#saihate-no-paladin-s2","title":"Saihate no Paladin (S2)","text":"<p>Score : 3/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#paradox-live-the-animation","title":"Paradox Live the Animation","text":"<p>Score : 3/7</p>"},{"location":"Anime/Anime%20log/2023/Fall/#kawagoe-boys-sing","title":"Kawagoe Boys Sing","text":"<p>Score : 2/7</p>"},{"location":"Anime/Anime%20log/2023/Spring/","title":"Spring 2023","text":""},{"location":"Anime/Anime%20log/2023/Summer/","title":"Summer 2023","text":""},{"location":"Anime/Anime%20log/2023/Winter/","title":"Winter 2023","text":""},{"location":"Anime/Anime%20log/2024/","title":"2024 anime","text":""},{"location":"Anime/Anime%20log/2024/Fall/","title":"Fall 2024","text":""},{"location":"Anime/Anime%20log/2024/Spring/","title":"Spring 2024","text":""},{"location":"Anime/Anime%20log/2024/Summer/","title":"Summer 2024","text":""},{"location":"Anime/Anime%20log/2024/Winter/","title":"Winter 2024","text":""},{"location":"Anime/Anime%20log/older/","title":"older","text":""},{"location":"Chess/Benko%20Declined/","title":"Benko Declined","text":"<p>The Benko Gambit is an opening for black which begins with 1. d4 Nf6 2. c4 c5 3. d5 b5 leading to the following position.</p> <p>cxb5 leads to the accepted variation. However, it is often the case that white declines, and there are very many ways to do so (ranked in order of frequency) :</p> <ul> <li>b3</li> <li>Nc3</li> <li>e3</li> <li>Qc2</li> <li>Nf3</li> <li>a4</li> <li>Nd2</li> <li>Bg5</li> </ul> <p>It is also possible for white to divert before reaching this position by not playing 3. d5. The alternatives are :</p> <ul> <li>Nf3</li> <li>e3</li> <li>dxc5</li> </ul>"},{"location":"Chess/Benko%20Declined/3.%20Nf3/","title":"3. Nf3","text":"<p>This position can also be reached via the English (1. c4 c5 2. Nf3 Nf6 3. d4)</p> <p>Black should continue ... cxd4 4. Nxd4 e5. The theoretical move is Nb5 (but more commonly played is Nb3) the position after black replies with d5 is equal.</p> <p>5. Nb5 d5 6. cxd5 Bf5 (not ... Nxd5 7. Qxd5 Qxd5 8. Nc7+). Here are a few things black should keep note of in this position:</p>"},{"location":"Chess/Benko%20Declined/3.%20Nf3/#1-resist-the-urge-to-kick-the-b5-knight-out","title":"1. Resist the urge to kick the b5 knight out","text":"<p>This is because white wants to play N5c3 anyway to defend the d pawn (which will be vulnerable after black castles). If white at any point brings his other knight out to defend the d pawn (N1c3), then it is alright to play a6 since the knight's preferred retreating square has been blocked.</p>"},{"location":"Chess/Benko%20Declined/3.%20Nf3/#2-bishop-sacrifice-on-d4","title":"2. Bishop sacrifice on d4","text":"<p>A game may likely continue 7. e3 O-O 8. N5c3 Bf5 9. a3 Nbd7 (with the intention of Nb6 to add further pressure to the d pawn) 10. Nd2. The idea here is to open the king up, play Re8, force Be2, and pressure the pinned bishop. Black can accomplish this with ... Bd4 11. exd4 exd4 12. Nb5 Re8+ 13. Be2 d3. The bishop sacrifice is not the best move, in fact black is slightly worse if white rejects the sacrifice: 11. Nb5 Bb6 12. Nc4. If you want to play more solidly as black, then do Rc8 instead of Bd4.</p> <p>Still, it can act as a nice surprise and it is helpful to look out for this idea in other positions.</p>"},{"location":"Chess/Benko%20Declined/3.%20Nf3/#3-attack-f2","title":"3. Attack f2","text":"<p>This is best done after g3 is played, signalling the bishop fianchetto and kingside castle. For example: 7. N5c3 O-O 8. g3 Qb6 9. e3 Bg4 10. Be2 Bxe2 11. Qxe2 e4. and black is doing fine.</p>"},{"location":"Chess/Benko%20Declined/3.%20Nf3/#4-how-to-deal-with-nf3","title":"4. How to deal with Nf3","text":"<p>Earlier, we mentioned that 5.Nf3 is more common than Nb3. The position is slightly better for black and here is how a typical game would go: .. Nc6 6.e3 d5 7.Be2 d4 8.exd4 e5 9. Ne5 Nxd4 10. O-O Bc5 11. Nc3 Qe7 12. Bf4 O-O. Notice that white's knight on e5 is trapped (Ng4 is not possible because of Nxe2+) and black can win if they keep pressuring the knight.</p>"},{"location":"Chess/Positions/","title":"Positions","text":"<p>Here I will document interesting positions (mostly from my online games) and provide some comments/analysis. In the future when there are many more positions I will figure out some sort of methodology to classify them, but for now all everything will be in one pile.</p>"},{"location":"Chess/Positions/#a-queen-sacrifice","title":"A queen sacrifice","text":""},{"location":"Chess/Positions/queensac/","title":"I sacrificed my queen","text":"<p>As you can see, I don't have a queen. No it was not some calculated clever sacrifice, it just got trapped and I did the best I could to win as much material back.</p> <p>I got a rook, knight, and a pawn for my queen which is not terrible. I still ended up losing the game, but there were a couple moments where I could have seized the advantage, including this one right here.</p>"},{"location":"Chess/Positions/queensac/#solution","title":"Solution","text":"<p>White's plan can be broken down into two objectives:</p> <ul> <li>Send the black king and queen to the 8th rank (with the king to the left of the queen)</li> </ul> <p>this sets up a skewer along the 8th rank, Rd8+ will win the queen except the black knight is gurading d8, hence..</p> <ul> <li>Kick the black knight out of its square</li> </ul> <p>This narrows our choices down to Rd6 (which kicks the knight out), Bd3 (which forces the queen back), and Nh5+ (which forces the king back). The correct sequence involves some combination of these moves.</p> <p>23. Bd3 Qg8 already fails the first objective since upon kicking the king back, it can tuck itself to the right of the queen on h8. More than that, Bd3 blocks the rook so it is not optimal.</p> <p>23. Nh5+ fails not because of .. Kg6 since 24. Nh4+ Kg5 25. g3! threatening mate with f4, and .. Bg4 doesn't work because of 26. Bxg4 Kxg4 27. Nf6+. Rather, after .. Kf8 24. Rd6 there is .. Qg6, instead of allowing white's plan (of kicking the black knight), black counterattacks our knight.</p> <p>This leaves 23. Rd3. There is no way to defend the knight, what makes the most sense is .. Nd4. Now we have to choose between Bd3 and Nh5+. </p> <ul> <li> <p>Bd3 fails on account of Qg8 as in previously. </p> </li> <li> <p>24. Nh5+ forces the king back, ..Kh8 fails because of 25. Rd8+. This leaves Kf8 or Kg8, which sets up the skewer once the queen is kicked back.</p> </li> </ul> <p>Let's say .. Kf8 25. Bd3, since queen back to the 8th rank is unacceptable, black has to block our bishop. There are three ways to do this:</p> <ol> <li> <p>.. Bf5, but Black loses a piece after 26. Nxd4 cxd4 27. Nf6 Qg7 28. Bxf5 the alternative .. Bxd3 27. Rd8+ Ke7 28. Nc6+ Ke6 29. Rxd3 also does not work out for black.</p> </li> <li> <p>.. Nf5. Notice that g4 does not work because Nxd6 Bxh7 Bxg4 leads to a drawn endgame. We can improve on this by moving our rook away with tempo which we can do via 26. Rd8+ Ke8 27. Rf8!! Kd6 and now g4 works (Qg6 can be met with h3).</p> </li> <li> <p>.. f5 leaves the bishop hanging after Nxd4.</p> </li> </ol> <p>Black can also try .. Qd6 in response to 23. Rd3, the idea is to meet Rxc3 with Ba2+, the resulting endgame still favors white albeit with a mere +1.3 valuation.</p> <p>A better resposne is to refrain from capturing the knight and playing 24. b3 stopping the Ba2+ idea from earlier, and reinforcing threat on the knight. Black is toast after .. Nd4 25. Bd3.  </p> <p>Link to full game</p>"},{"location":"Chess/Tips/","title":"Tips","text":"<p>Generally useful tips to keep in mind :</p>"},{"location":"Chess/Tips/#how-to-handle-anti-sicilians","title":"How to handle anti-sicilians","text":""},{"location":"Chess/Tips/antisicilian/","title":"Antisicilian","text":"<p>Daniel Naroditsky recommends the Botvinnik system as a set-up against most anti-sicilians. See the following video (at 29:48) for a breakdown</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/","title":"Japanese Section \ud83d\uddfe","text":"<p>\\(\\small \u3053\u3093\u306b\u3061\\)-what's up! This is the japanese section where you can find all to do with Japan (except anime; because honestly that requires its own section). This includes bits of Japanese culture I find interesting, and also some resources to do with learning Japanese. I am still learning myself so there might be inaccuracies when I present or translate relevant information.</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/#-japanese-language-learning-resources","title":"- Japanese Language Learning Resources","text":""},{"location":"Japanese%20Section%20%F0%9F%97%BE/Annotated/","title":"Annotated Videos","text":"<p>Here are some Japanese videos that I have annotated which can be used as learning material. Of course I do not claim that these annotations are perfect, so take it with a grain of salt.</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Annotated/#-","title":"- \u30de\u30b8\u3067\u9053\u8349\u98df\u3063\u3066\u308b\u3084\u3064","text":""},{"location":"Japanese%20Section%20%F0%9F%97%BE/Resources/","title":"Japanese Language Learning Resources","text":"<p>This is a curated list of Japanese language learning resources I find to be helpful</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Resources/#cool-language-learning-websites","title":"Cool Language Learning Websites","text":"General Guides <ul> <li>TheMoeWay</li> <li>Immersion-Based Japanese Learning</li> <li>JP Lazy Guide</li> <li>Itazuraneko -&gt; alt</li> <li>Tatsumoto Ren -&gt; alt</li> <li>IgrecL</li> <li>animecards</li> </ul> Grammar <ul> <li>Ixrec's Guide to Japanese</li> <li>Tae Kim's Guide to Learning Japanese</li> <li>Core6000</li> <li>japbase</li> <li>boirodaisuki</li> </ul> <p>Most of these websites generally have the same content, but the most complete is probably TheMoeWay, Tatsumoto Ren, and Itazuraneko. For grammar specifically, japbase and Tae Kim's Guide is good.</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Resources/#books-manga-etc","title":"Books, Manga, etc...","text":"<ul> <li>Itazuraneko</li> <li>Bilingual Manga</li> <li>Manga Zip -&gt; alt</li> <li>Dlraw</li> <li>rawkuma</li> <li>mangaz</li> <li>nhentai</li> <li>hitomi</li> <li>aarinfantasy - BL stuff</li> <li>anime-sharing</li> <li>nyaa.si<ul> <li>sukubei - nyaa.si with NSFW included</li> </ul> </li> </ul> Paid (but occasionally has free stuff too) <ul> <li>A guide on buying japanese ebooks</li> <li>booklive</li> <li>cmoa</li> <li>ebookjapan</li> <li>pixiv</li> <li>amazon.co.jp</li> </ul>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Resources/#tools","title":"Tools","text":"Dictionary <ul> <li>yomitan - Pop-up dictionary for browser</li> <li>jpdb - Dictionary</li> </ul> Subtitles <ul> <li>asbplayer - Add subtitles to streaming videos</li> <li>jimaku.cc - jp subtitles</li> </ul> OCR <ul> <li>mokuro - Manga ocr</li> <li>YomiNinja - Screen ocr (for Japanese video games)</li> <li>textractor - (not OCR) extracts text from software</li> </ul> Example sentence search <ul> <li>sentencesearch</li> <li>massif.la</li> <li>immersionkit - example sentences from anime</li> <li>youglish - example sentences from YouTube</li> </ul>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Resources/#youtube-channels-with-jp-subs","title":"Youtube Channels with JP subs","text":"BL stuff (WHY ARE THERE SO MANY!! GAHH) <ul> <li>BL sandwich</li> <li>BL skip</li> <li>BL kiss</li> <li>gyu BL</li> <li>CIEL BL - has furigana, very helpful</li> <li>After school</li> <li>moving BL</li> <li>KYOMUO</li> <li>Blooming magic</li> <li>BL diary</li> <li>BL animal park</li> <li>iketen</li> <li>BL student council</li> <li>Mickymacky</li> <li>BL and Gente</li> <li>Gush and Emo</li> </ul> Animations <ul> <li>Paranormal HS</li> <li>MariMariMari</li> <li>Pyutifi</li> <li>Lovelysomeday</li> <li>HundredNote<ul> <li>Snake Pit</li> <li>Hawk Eyes</li> <li>Swallow Tail</li> </ul> </li> <li>Chrono reverse</li> <li>tasukukoma</li> </ul> Others <ul> <li>EGA channel</li> <li>Japanese with Shun</li> <li>Moshi Moshi Yusuke</li> </ul> <p>I also occasionally annotate Japanese videos, e.g, highlighting relevant vocabulary, explaining contexts, etc...</p>"},{"location":"Japanese%20Section%20%F0%9F%97%BE/Annotations/vid1/","title":"\u30de\u30b8\u3067\u9053\u8349\u98df\u3063\u3066\u308b\u3084\u3064","text":"<p>Relevant Vocabulary:</p> <ul> <li> <p>START :</p> <p> \u76e3\u7763 <ul> <li>boss, supervisor, coach, etc..</li> <li>-suru verb (to supervise)      \u90e8\u6d3b </li> <li>club (school), extracurricular      \u9053\u8349\u3092\u98df\u3046 </li> <li>A japanese proverb : to loiter around (while on the way to somewhere)</li> <li>Literally this means : to eat roadside grass      \u5bc4\u308a\u9053 </li> <li>detour</li> <li>-suru verb (to take a detour)      \u771f\u5263 </li> <li>seriously, earnestly</li> <li>real sword (as opposed to practice sword)      \u30b5\u30dc\u308b </li> <li>Shortening of \"sabotage\" (\u30b5\u30dc\u30bf\u30fc\u30b8\u30e5) </li> <li>to slack off, skip class, etc...      \u6cb9\u3092\u58f2\u308b </li> <li>Another Japanese proverb : loafing around, slacking off, etc..</li> <li>Literally : to sell oil      \u7121\u99c4\u8a71 </li> <li>chit-chat, gossip      \u7e41\u76db </li> <li>thriving, flourishing      \u534a\u984d </li> <li>half price      \u58f2\u308a\u5207\u308c\u308b </li> <li>to be sold out      \u6642\u9593\u3092\u6f70\u3059 </li> <li>to kill time</li> <li>\u6f70\u3059 : to smash, crush, slaughter (livestock), etc...      \u7269\u7406\u7684\u306b </li> <li>physically, literally      \u6687 </li> <li>free time, spare time      \u5727\u7e2e </li> <li>compression</li> <li>-suru verb (to compress)      \u6642\u306e\u6d41\u308c </li> <li>the flow of time   </li> </ul>"},{"location":"Maths/","title":"Maths","text":"<p>ZFC (Zermelo-Fraenkel + choice) is the most commonly used foundation of mathematics, and I don't like it. I much prefer to think about mathematics in the framework of type theory. If you don't know what type theory is, I suggest you give a quick skim of the wikipedia page before continuing.</p> <p>Switching to this framework was no easy task, it is a difficult and relatively new field. Further, there are so many different versions of type theory, and with no clear dominant version you may be learning type theory from one resource and upon switching to a different resource find that a completely different approach is used. Still, it is worth it because type theory is a much more natural framework for mathematics than ZFC.</p> <p>The version of type theory I am most comfortable with is the one that is implemented in Lean Prover, an interactive theorem proving software with an existing library of computerized definitions and proofs from a standard undergraduate curriculum. There is also plenty of documentation to aid with learning how to use the language. </p> <p>Still, my understanding of type theory doesn't exactly match that of Lean's. In fact, it is a very dumbed down version of it because I still can't understand some aspects of the language.</p> <p>I will try to outline type theory based on my current rudimentary understanding at a separate section. This includes explaining a syntax (which is quite similar to Lean's) which I use to deal with mathematics in a type-theoretic framework. I do this because all my future posts on mathematics will feature this syntax and framework.  </p> <p>It is important to note that how I currently view type theory may not be accurate and some details may be overlooked, this is mostly on purpose because I don't understand enough to talk about it. </p> <p>For example, I will treat an aspect I don't understand as some sort of black box. </p> <p>Without further ado, click here for an outline of type theory as I see it. </p>"},{"location":"Maths/Metric%20Spaces/Continuity/","title":"Continuity","text":""},{"location":"Maths/Metric%20Spaces/Continuity/#def-11","title":"Def 1.1","text":"<p>Definition. If \\(X\\) and \\(Z\\) are two metric spaces, then a function \\(f:X\\to Z\\) is continuous at a point \\(a:X\\) if for every \\(\\epsilon&gt;0\\) there exists a \\(\\delta&gt;0\\) such that for any \\(x:X\\),</p> \\[d(a,x)&lt;\\delta \\Longrightarrow d(f(a),f(x))&lt;\\epsilon\\] <p></p> <p>If \\(f:X\\to Z\\) is continuous at all points of \\(X\\), that is to say : <code>\u2200x:X, is_cont f x</code>, then we simply say that \\(f\\) is continuous (on \\(X\\)).</p> <p>An equivalent (arguably better) defintion is : \\(f\\) is continuous at \\(a\\) iff for every \\(\\epsilon&gt;0\\) there exists a \\(\\delta&gt;0\\) such that</p> \\[ f[B(a,\\delta)] \\subseteq B(f(a),\\epsilon) \\]"},{"location":"Maths/Metric%20Spaces/Continuity/#prop-12","title":"Prop 1.2","text":"<p>Proposition. If \\(X\\) and \\(Z\\) are metric spaces and \\(f:X\\to Z\\), then \\(f\\) is continuous at a point \\(a:X\\) iff whenever \\(x:\\) seq \\(X\\), \\([x\\to a]\\) then \\(f\u2218x\\to f(a)\\).</p> <p></p>"},{"location":"Maths/Metric%20Spaces/Continuity/#proof","title":"Proof","text":"Step 1   Step 2   Step 3   Step 1 (reverse)   Step 2  \u00ab \u00bb"},{"location":"Maths/Type%20Theory/","title":"Type Theory","text":""},{"location":"Maths/Type%20Theory/#part-1-introduction","title":"Part 1 - Introduction","text":""},{"location":"Maths/Type%20Theory/#part-2-type-creation","title":"Part 2 - Type Creation","text":""},{"location":"Maths/Type%20Theory/#part-3-dependent-types","title":"Part 3 - Dependent Types","text":""},{"location":"Maths/Type%20Theory/#part-4-more-types","title":"Part 4 - More Types","text":""},{"location":"Maths/Type%20Theory/#part-5-the-natural-numbers","title":"Part 5 - The Natural Numbers","text":""},{"location":"Maths/Type%20Theory/#part-6-universes","title":"Part 6 - Universes","text":""},{"location":"Maths/Type%20Theory/#part-7-propositions","title":"Part 7 - Propositions","text":""},{"location":"Maths/Type%20Theory/#part-8-propositional-truncation","title":"Part 8 - Propositional Truncation","text":""},{"location":"Maths/Type%20Theory/#_1","title":"...","text":""},{"location":"Maths/Type%20Theory/part1/","title":"Part 1 - Introduction","text":"<p>In type theory there are two kinds of objects: terms and types. A term is something that is contained in a type and a type is something that contains terms. For instance, the following illustrates a type called <code>A</code> which contains three terms: <code>a\u2081, a\u2082, a\u2083</code>.</p> <p></p> <p>One may notice a heavy similarity to set theory but there are various key differences. In set theory, every object is a \"set\" and I like to think that these objects behave like a term and a type simultaneously, that is to say they can act as objects inside containers, whilst also being able to act as containers themselves.</p> \\[ a \\in A \\in \\{A\\} \\] <p>The above shows a set \\(A\\) serving as a container (containing the element (set) \\(a\\)). At the same time, \\(A\\) serves as an object contained in the set \\(\\{A\\}\\).</p> <p>In type theory there is a separation between objects that act like containers (types) and the contained objects (terms). I think of type theory as a 2-level system, that is to say, if <code>A</code> is a type then there is no \"higher-level\" object that can contain <code>A</code> since it is already the highest level object. Similarly, a term cannot act as a container for another object because it is the lowest level object.</p> <p>This is a naive view of type theory. In truth, there is a cumulative hierarchy of universes, much like Von Neumann universes. We will adopt this naive view for now and completely switch gears at some point.</p> <p>It is also important to note that a term has to always be associated to the type that it is contained in, that is to say, one cannot introduce a term <code>a</code> without reference to the type that it is contained in. The notation \"<code>a:A</code>\" is used to express that a term <code>a</code> is contained in a type <code>A</code>. Whilst in set theory it is acceptable (but perhaps not good practice) to mention the object \\(1:=\\{\\varnothing\\}\\) without the context that \\(1\\in \\mathbb{N}\\)<sup>1</sup>, it is nonsense to speak of a term <code>a</code> without reference to the type that it is contained in. Whenever we introduce a term, we do so by writing <code>a:A</code>, forcing us to make reference to a type <code>A</code> which contains the term. If I write <code>a</code> on its own, this means that it should be clear from context what the type of <code>A</code> is.</p> <p>In type theory, a term is also uniquely contained in one type, that is to say we cannot have both <code>a:A</code> and <code>a:B</code> unless <code>A := B</code>. One may then ask: if we think of \\(\\mathbb{N}\\) and \\(\\mathbb{Z}\\) as types then don't we have both <code>1:\u2115</code> and <code>1:\u2124</code>? The way type theory deals with this is to have different terms represent the multiplicative identity of \\(\\mathbb{N}\\) and \\(\\mathbb{Z}\\) (even if they have the same symbol)<sup>2</sup>. If we want to be ultra-precise we may use the symbols <code>\u2115(1)</code> and <code>\u2124(1)</code> to refer to these two terms, but this is really no issue, ideally there is always enough context to clear up any confusion.</p> Side Note: <p>At first glance this appears to pose some problems. For example if we have a function <code>f:\u2124\u2192\u2124</code> (a mapping between terms of type <code>\u2124</code> to terms of type <code>\u2124</code>)<sup>3</sup>, it doesn't make sense (in type theory) to use <code>1:\u2115</code> as an input for this function because of the type mismatch. This is an annoying feature, but can be fixed easily with coercions. </p> <p>The basic idea is as follows: to express the idea (from set theory) that \\(\\mathbb{N}\\subseteq \\mathbb{Z}\\) in terms of type theory, one can specify a function <code>\u03b9:\u2115\u2192\u2124</code> (called a coercion from <code>\u2115</code> to <code>\u2124</code>) such that the term <code>1:\u2115</code> is mapped to the term <code>1:\u2124</code> and so on. To view/treat a term of type <code>\u2115</code> as a term of type <code>\u2124</code> one just needs to apply the function <code>\u03b9:\u2115\u2192\u2124</code> to that term. We may not be able to use <code>1:\u2115</code> as an input for <code>f:\u2124\u2192\u2124</code> but an equivalent alternative is to use <code>\u03b9(1):\u2124</code> as the input instead. Going the other way around (viewing terms of type <code>\u2124</code> as terms of type <code>\u2115</code>) is less straightforward and will be discussed later, as well as more details regarding coercions.</p> <p>Before continuing let us write <code>A:Type</code> to specify that <code>A</code> is a type. Notice that the colon in <code>a:A</code> and <code>A:Type</code> are functionally different. That is, while <code>a</code> is thought of as contained in <code>A</code>, we don't think of <code>A</code> as being contained an object called <code>Type</code>. </p> <p>Another key idea in type theory is the equivalence between propositions and types (the proposition as types interpretation). For example, statements ranging from <code>RH</code> (Riemann's Hypothesis) to <code>\u2200n:\u2115,\u2203m:\u2115, m&gt;n</code> are all types, i.e, <code>RH:Type</code> and <code>\u2200n:\u2115,\u2203m:\u2115, m&gt;n:Type</code>, etc... But on the flip side this means that <code>\u2115:Type</code> can be viewed as a proposition, and it is not entirely clear what this means. I am not too confident with my ability to explain this topic, but here is a stackexchange post that goes into detail.</p> <p>In some alternate approaches we can only interpret types with at most one term as propositions. This is known as the proposition as some types interpretation. We will actually switch to this interpretation later on for reasons to be explained later.</p> <p>If <code>A:Type</code> is to be interpreted as a proposition, then what are its terms supposed to be? The terms of <code>A</code> are given by the proof(s) of <code>A</code>. In other words, <code>A</code> is true iff it is a nonempty type and false otherwise. This idea seems weird at first, but it will be explained more precisely at some later section. The point is that type theory gives us the ability to treat proofs and propositions as mathematical objects in the exact same way we treat numbers as mathematical objects, and it is this idea that makes type theory more suitable for theorem proving software than set theory or other alternatives.</p> <p>That is it for a brief overview of type theory. In the next section we go over the process of creating / building a type.</p> <p>Next Section</p> <ol> <li> <p>In the same vein that it is acceptable to mention \\(\\varnothing\\) without reference to some larger set it is a part of.\u00a0\u21a9</p> </li> <li> <p>Similar to how we use the same symbol \\(+\\) to denote addition between elements of \\(\\mathbb{R}\\) and addition between elements of \\(\\mathbb{R}^2\\) even though they count as two different operators.\u00a0\u21a9</p> </li> <li> <p>Precisely what a function is in terms of type theory will be discussed later, but right now the details don't matter. We all know how a function is supposed to work and this is no different in type theory than it is in set theory.\u00a0\u21a9</p> </li> </ol>"},{"location":"Maths/Type%20Theory/part2/","title":"Part 2 - Type Creation","text":"<p>Just like how in set theory we need to get started by asserting the existence of the empty set \\(\\varnothing\\), we too need to populate our type system with some base types in order to start doing mathematics. The process for type creation involves specifying four rules:</p> <ul> <li>Type formation rule : assert the existence of the type you want to create</li> <li>Term introduction rule : specify how terms of the type are constructed</li> <li>Term elimination rule : specify how to convert terms of the type to terms of another</li> <li>Computation rule : specify equalities which aid in simplification</li> </ul> <p>Let us use the empty type <code>\ud835\udfd8:Type</code> as a case example. As you would have guessed the empty type is a type that contains no terms, we shall specify the four rules accordingly to allow for this property.</p> <p>The rules are given in the following form:</p> \\[ \\frac{\\text{[Premise]}}{\\text{[Conclusion]}} \\] <p>This expression states that whenever the premises (which can be thought of as preconditions) have been obtained or satisfied, we may take the conclusion for granted.</p>"},{"location":"Maths/Type%20Theory/part2/#type-formation-rule-for-0type","title":"Type formation rule for <code>\ud835\udfd8:Type</code>","text":"\\[ \\frac{}{\\text{0:Type}} \\] <p><sup>1</sup> The above expression means: \"there is no need for any precondition to be satisified, we simply have <code>\ud835\udfd8:Type</code>\". By specifying this rule, we have asserted the existence of the empty type.</p>"},{"location":"Maths/Type%20Theory/part2/#term-introduction-rule-for-0type","title":"Term introduction rule for <code>\ud835\udfd8:Type</code>","text":"\\[ \\text{- - none - -} \\] <p>Notice that since <code>\ud835\udfd8:Type</code> is supposed to have no terms, we don't need to specify how its terms are constructed. </p>"},{"location":"Maths/Type%20Theory/part2/#term-elimination-rule-for-0type","title":"Term elimination rule for <code>\ud835\udfd8:Type</code>","text":"<p>You may think that there should be no need for a term elimination rule as well, but it is helpful to introduce one so that we may model the principle of ex falso quodlibet into our type system.</p> <p>For those unaware, ex falso quodlibet is latin for \"from falsehood, anything\" it is more commonly referred to as the priniciple of explosion. In the context of logic, this means that whenever a contradiction is derived, any proposition can be inferred. </p> <p>With the proposition as types interpretation, we may transfer this principle into type theory. If we view <code>\ud835\udfd8:Type</code> as a false proposition (of course there are no terms (proofs) for <code>\ud835\udfd8:Type</code> so this makes sense), then observe that <pre><code>whenever a contradiction is derived, any proposition can be inferred\n</code></pre> can be interpreted as : <pre><code>a proof of falsehood brings forth a proof of any propostion\n</code></pre> then using the equivalences : </p> <ul> <li><code>falsehood \u2194 \ud835\udfd8:Type</code></li> <li><code>proof \u2194 term</code></li> <li><code>proposition \u2194 Type</code></li> </ul> <p>we get :</p> <pre><code>a term of `\ud835\udfd8:Type` generates a term of any type\n</code></pre> <p>The above statement tells us how to specify our term elimination rule. This can be done like so :</p> \\[ \\frac{x:0 \\ , \\quad \\text{A : Type}}{\\text{rec}_{\\text{0}}(x):\\text{A}} \\] <p>the above expression translates to: \"given any <code>x:\ud835\udfd8</code> and any <code>A:Type</code>, one may generate a term <code>rec\u2080(x)</code> of type <code>A</code>\". The <code>rec</code> stands for recursion (induction). Later on we'll see that the term elimination rule for <code>\u2115:Type</code> corresponds to natural number induction. We can think of the term elimination rule as some form of generalized induction. </p>"},{"location":"Maths/Type%20Theory/part2/#computation-rule-for-0type","title":"Computation rule for <code>\ud835\udfd8:Type</code>","text":"\\[ \\text{- - none - -} \\] <p>It is often the case that the computation rule specifies what happens if we apply the term elimination rule to the term introduction rule, but since we have no term introduction rule, there is no need for a computation rule as well.</p>"},{"location":"Maths/Type%20Theory/part2/#conclusion","title":"Conclusion","text":"<p>As an ending note let us compare the set \\(\\varnothing\\) with <code>\ud835\udfd8:Type</code>. The ex falso quodlibet principle in set theory corresponds to the following :</p> \\[ \\forall x, \\quad  x\\in \\varnothing \\Longrightarrow P \\] <p>where \\(P\\) can be any proposition. The above is simply a special form of the tautology :</p> \\[ \\neg A \\Longrightarrow (A \\Longrightarrow B) \\] <p>Thus ex falso quodlibet  is a consequence of the underlying first order logic that set theory is built off. On the other hand, the term elimination rule for <code>\ud835\udfd8:Type</code> is not dependent on any sort of underlying system (in fact, type theory has no underlying system), but it is rather an intrinsic property of <code>\ud835\udfd8:Type</code> itself which is true by construction.</p> <p>The idea is that a type should not be thought of simply as a container for terms. Through its introduction, elimination, and computation rules, it represents a richer structure.</p> <p>Previous Section</p> <p>Next Section</p> <ol> <li> <p>Since KaTeX cannot render <code>\ud835\udfd8</code> we use the standard zero instead\u00a0\u21a9</p> </li> </ol>"},{"location":"Maths/Type%20Theory/part3/","title":"Part 3 - Dependent Types","text":"<p>A dependent type is a type that is determined by the terms of some other type. For example, if <code>B</code> is a dependent type over <code>A:Type</code> with <code>a\u2081,a\u2082,a\u2083:A</code> then what type <code>B</code> is depends on which term of <code>A</code> is fed into it, that is, each <code>B(a\u2081), B(a\u2082), B(a\u2083)</code> are typically (but not necessarily) distinct types. The following diagram illustrates this</p> <p></p> <p>We use the notation :</p> \\[ x:A \\vdash B(x):\\text{Type} \\] <p>to mean \"<code>B</code> is a dependent type over <code>A</code>\". An example of a dependent type is <code>n:\u2115 \u22a2 vec(n):Type</code>. Depending on a term <code>n:\u2115</code>, we define <code>vec(n):Type</code> to be the type with terms consisting of n-dimensional vectors over \\(\\mathbb{R}\\). </p> <p>For example, <code>vec(2)</code> is a type consisting of the terms <code>[-1,0], [0,\u03c0] , etc..</code> and in <code>vec(3)</code> we have <code>[1,-2,3], [0,0,0], etc..</code> and so on..</p> <p>Of course there could be cases where <code>x:A \u22a2 B(x):Type</code> but <code>B</code> is constant no matter what <code>x:A</code> we feed into it. It is still valid to call <code>B</code> a dependent type even in this scenario. More specifically, <code>B</code> is a constant dependent type. </p>"},{"location":"Maths/Type%20Theory/part3/#dependent-product-type","title":"Dependent Product Type","text":"<p>The idea is, given a dependent type <code>x:A \u22a2 B(x):Type</code>, we would like to create a new type consisting of terms which maps any <code>a:A</code> to a term of type <code>B(a)</code>.</p> <p>Again, to create this type we specify the four rules :</p>"},{"location":"Maths/Type%20Theory/part3/#type-formation-rule","title":"Type formation rule","text":"\\[ \\frac{x:\\text{A} \u22a2 \\text{B}(x):\\text{Type}}{\\prod_{x:A} \\ B(x) : \\text{Type}} \\] <p>\"Given a dependent type <code>B</code> over some <code>A:Type</code>, one may form the type <code>\u220fx:A B(x)</code>, called the dependent product type for <code>B</code>\"</p> <p>We could add in <code>A:Type</code> at the top bar to be more explicit but that is not necessary. Simply by stating <code>x:A \u22a2 B(x):Type</code> we already know implicitly that <code>A</code> must be referring to a type.</p>"},{"location":"Maths/Type%20Theory/part3/#term-elimination-rule","title":"Term elimination rule","text":"\\[ \\frac{f:\\prod_{x:A} B(x), \\quad a:\\text{A}}{f(a):B(a)} \\] <p>\"Given a term <code>f</code> of the dependent product type and a term <code>a:A</code>, one may apply <code>f</code> to <code>a</code> to obtain a term of <code>B(a)</code>. The result of this application is written <code>f(a)</code>\"</p>"},{"location":"Maths/Type%20Theory/part3/#term-introduction-rule","title":"Term introduction rule","text":"<p>How should we construct a dependent product type? The answer lies in lambda calculus. We shall provide a brief overview :</p> <p>Given an expression <code>t</code> involving a free variable <code>x:A</code> (sometimes we write <code>t[x]</code> to make the involvement of <code>x:A</code> more explicit), we may form what is called a lambda abstraction : $$ \\lambda x:A,  t $$ The type of <code>t</code> may or may not depend on the choice of the free variable <code>x:A</code>, we can of course express this with a dependent type. We write <code>x:A \u22a2 t[x]:B(x)</code> where <code>B</code> is some dependent type to mean that <code>t</code> is an expression involving a free variable <code>x:A</code> with the type <code>B(x)</code></p> <p>Example: $$ \\lambda x:\u2115,  x+1 $$ here, the lambda abstraction consists of the free variable <code>x:\u2115</code> with the expression <code>x+1</code>. The expression's type in this case is not dependent on the choice of <code>x:\u2115</code>, of course <code>x+1</code> has type <code>\u2115</code> regardless of whatever <code>x:\u2115</code> is.</p> <p>Given a lambda abstraction <code>\u03bbx:A, t[x]</code> where <code>x:A \u22a2 t[x]:B(x)</code> and a term <code>a:A</code> one may apply this lambda abstraction to <code>a</code> to produce a term of type <code>B(a)</code>. The result of this application is denoted <code>\u03bbx:A, t[x] (a) := t[a]</code> where <code>t[a]</code> is the result of switching all instances of the free variable <code>x:A</code> in the expression with <code>a</code>. </p> <p>For example : $$ (\\lambda x:\u2115,  x+1)  (3) := 4+1 $$ Notice then that lambda abstractions are exactly what we want as the terms of our dependent product thus we come up with the following term introduction rule : $$ \\frac{x:\\text{A} \u22a2 t[x]:\\text{B}(x)}{\u03bbx:\\text{A},  t[x]:\\prod_{x:\\text{A}} B(x)} $$ \"Given <code>x:A \u22a2 t[x]:B(x)</code>, i.e, an expression <code>t[x]:B(x)</code> involving <code>x:A</code> as a free variable, the lambda abstraction <code>\u03bbx:A, t[x]</code> is a term of the dependent product type\"</p>"},{"location":"Maths/Type%20Theory/part3/#computation-rule","title":"Computation rule","text":"\\[ \\frac{a:\\text{A}, \\quad x:\\text{A} \u22a2 t[x]:\\text{B}(x)}{\u03bbx:\\text {A}, t[x] \\ (a) := t[a] : B(a)} \\] \\[ \\frac{f:\\prod_{x:\\text{A}} B(x)}{f := \u03bbx:\\text{A}, f(x) : \\prod_{x:\\text{A}} B(x)} \\] <p>There are two computation rules which are mostly self-explanatory. The first one specifies that application of a lambda abstraction to a term is simply a substitution process. The second one states that any term of the dependent product type is itself a lambda abstraction. </p>"},{"location":"Maths/Type%20Theory/part3/#connection-to-the-quantifier","title":"Connection to the quantifier \u2200","text":"<p>Let <code>x:A \u22a2 B(x):Type</code> and <code>f:\u220fx:A B(x)</code>. Further suppose that the type <code>B(x)</code> is a predicate on <code>x:A</code>, for example if <code>A = \u2115</code> we could define <code>x:\u2115 \u22a2 B(x) := x&lt;5</code>. </p> <p>Remember that since <code>x&lt;5</code> is a proposition it can be viewed as a type as well</p> <p>Going back to the general case, what does the existence of an <code>f:\u220fx:A B(x)</code> indicate? If we have such a term on hand then we can apply <code>f</code> to any term <code>a:A</code> to obtain <code>f(a):B(a)</code> where <code>f(a)</code> can be viewed as a proof of the proposition <code>B(a)</code>, that is, for any <code>a:A</code>, <code>f</code> generates a proof of <code>B(a)</code>. Thus, because we have a term <code>f:\u220fx:A B(x)</code>, we know that <code>B(a)</code> is true for all <code>a:A</code>. In some sense, <code>f</code> is a proof of <code>\u2200a:A, B(a)</code>, and if we use the proposition as types interpretation then <code>\u2200a:A, B(a) := \u220fx:A B(x) : Type</code>.</p> <p>Why is it called the dependent product type? Let us consider the case where there is a term <code>a:A</code> for which the proposition <code>B(a)</code> is not true, i.e, <code>B(a)</code> (viewed as a type) is empty. Then a term <code>f:\u220fx:A B(x)</code> is impossible to construct, i.e, the type <code>\u220fx:A B(x)</code> is empty. After all, <code>f</code> needs to map <code>a:A</code> to a term of type <code>B(a)</code> but there is none to map to. </p> <p>We can think of <code>\u220fx:A B(x)</code> as the \"multiplication\" of all the <code>B(x)'s</code> for each <code>x:A</code>. All it takes is for one of those <code>B(x)'s</code> to be empty in order for <code>\u220fx:A B(x)</code> to be empty as well. Of course, this is analogous to arithmetic multiplication where if one of the terms in the product is zero, then the whole product is zero as well</p> \\[0 = 123 \\times 6 \\times 0 \\times 23\\times \\cdots\\] <p>It is fitting then that an empty type be given the symbol <code>\ud835\udfd8</code>, and the dependent product type uses <code>\u220f</code> in order to reflect the similarity with regular arithmetic.</p>"},{"location":"Maths/Type%20Theory/part3/#function-types","title":"Function types","text":"<p>We finally define the function type. Given two types <code>A,B:Type</code> we may form the type <code>A\u2192B:Type</code> whose terms consists of functions / mappings of terms from <code>A</code> to terms from <code>B</code>. It turns out that we don't have to do any more work in constructing such a type because it already comes for free as a special case of the dependent product type.</p> <p>Let <code>x:A \u22a2 B(x):Type</code> and <code>f:\u220fx:A, B(x)</code> as illustrated below</p> <p></p> <p>Let us suppose we find out that <code>B</code> does not depend on <code>x:A</code>. This means that <code>B(x)</code> are all the same type for any <code>x:A</code>. Let's call this type simply <code>B</code>.. see what happens when the diagram reflects this change :</p> <p></p> <p>It looks like <code>f</code> simply reduces to a function from <code>A</code> to <code>B</code> and likewise this implies that the type <code>\u220fx:A, B(x)</code> reduces to <code>A\u2192B</code> if <code>B</code> is not dependent on <code>x:A</code>. </p> <p>I will not do it myself in this space but you may try to explicitly construct the function type anyway by specifying the four rules. It would be a good exercise to do so.</p>"},{"location":"Maths/Type%20Theory/part3/#dependent-sum-type","title":"Dependent Sum Type","text":"<p>While the dependent product type, <code>\u220f</code>, is analogous to <code>\u2200</code> the dependent sum type, <code>\u2211</code>, is analogous to <code>\u2203</code>. How do we want to create a type so that it matches the behaviour of <code>\u2203</code>? Suppose <code>x:A \u22a2 B(x):Type</code> then <code>\u2211x:A, B(x) := \u2203x:A B(x)</code> can be viewed as a type whose terms are proofs that there exists an <code>x:A</code> for which <code>B(x)</code> is true. </p> <p>A term (proof) of <code>\u2203x:A, B(x)</code> is thus composed of two parts. First, we'll need to provide some term <code>a:A</code>, then we need to provide a term <code>p:B(a)</code>, i.e, a proof of <code>B(a)</code>. This is how we will specify the term introduction rule.</p> <p>Next, we'll need to figure out how to \"use\" a term  of <code>\u2203x:A B(x)</code>. If <code>q:\u2203x:A B(x)</code> then it makes sense that we should be able to extract from <code>q</code> a term <code>a:A</code> and a proof <code>p:B(a)</code>. This is how we will specify the term elimination rule.</p>"},{"location":"Maths/Type%20Theory/part3/#type-formation-rule_1","title":"Type formation rule","text":"\\[ \\frac{x:\\text{A} \u22a2 \\text{B}(x):\\text{Type}}{\\sum_{x:A} \\ B(x) : \\text{Type}} \\] <p>\"Given a dependent type <code>B</code> over some <code>A:Type</code>, one may form the type <code>\u2211x:A B(x)</code>, called the dependent sum type for <code>B</code>\"</p>"},{"location":"Maths/Type%20Theory/part3/#term-introduction-rule_1","title":"Term introduction rule","text":"<p>$$ \\frac{a:\\text{A}, \\quad p:\\text{B}(a)}{(a,p):\\sum_{x:\\text{A}} \\text{B}(x)} $$ \"Given some <code>a:A</code> and <code>p:B(a)</code>, the combination <code>(a,p)</code> is a term of the dependent product type.\"</p>"},{"location":"Maths/Type%20Theory/part3/#term-elimination-rule_1","title":"Term elimination rule","text":"\\[ \\frac{q:\\sum_{x:\\text{A}} \\text{B}(x)}{\\pi_1(q):\\text{A}, \\quad \\pi_2(q):\\text{B}(\\pi_1(q))} \\] <p>\"Given a term <code>q</code> of the dependent sum type, one may decompose <code>q</code> back to the components they were constructed from as per the introduction rule. The functions <code>\u03c0\u2081</code> and <code>\u03c0\u2082</code> perform this action.\"</p>"},{"location":"Maths/Type%20Theory/part3/#computation-rule_1","title":"Computation rule","text":"\\[ \\frac{a:\\text{A}, \\quad p:\\text{B}(a)}{\\pi_1(a,p):=a:\\text{A}, \\quad \\pi_2(a,p):=p:\\text{B}(a)} \\] \\[ \\frac{q:\\sum_{x:\\text{A}}\\text{B}(x)}{q := (\\pi_1(q), \\pi_2(q)):\\sum_{x:\\text{A}}\\text{B}(x)} \\] <p>and here are the straightforward computation rules for the dependent sum type.</p> <p>The following diagram illustrates the dependent sum type :</p> <p></p> <p>Like the dependent product type, the dependent sum type can be thought of as \"summing\" all the <code>B(x)'s</code> for each <code>x:A</code>, so it makes sense that all of the <code>B(x)'s</code> would need to be empty for the total sum, <code>\u2211x:A B(x)</code>, to be empty as well.</p> <p>Previous Section</p> <p>Next Section</p>"},{"location":"Maths/Type%20Theory/part4/","title":"Part 4 - More Types","text":"<p>Now that we have covered dependent types this gives us more freedom of expression to define new types and redefine old ones. For example, dependent types allows us to provide an alternative term elimination rule for the empty type.</p> <p>Recall that in set theory :</p> \\[ \\forall x\\in \\varnothing, \\ \\text{B}(x) \\] <p>is true for any predicate \\(\\text{B}\\). If we interpret \\(\\forall\\) as the dependent product type, \\(\\varnothing\\) as the empty type and \\(\\text{B}\\) as a dependent type then we get the following rule :</p> \\[ \\frac{x:0\\vdash \\text{B}(x):\\text{Type}}{\\text{rec}_0:\\prod_{x:0} \\ \\text{B}(x)} \\] <p>\"Given a dependent type <code>B</code> over <code>\ud835\udfd8</code>, we obtain a term of type <code>\u220fx:\ud835\udfd8 B(x)</code>.\" Such a term corresponds to the empty function. The elimination rule here and the one presented earlier are essentially equivalent. </p>"},{"location":"Maths/Type%20Theory/part4/#the-unit-type","title":"The Unit Type","text":"<p>We would like to create a type which has only one term, this type will be called the unit type and be given the symbol <code>\ud835\udfd9</code>.</p>"},{"location":"Maths/Type%20Theory/part4/#type-formation-rule","title":"Type formation rule","text":"\\[ \\frac{}{1:\\text{Type}} \\]"},{"location":"Maths/Type%20Theory/part4/#term-introduction-rule","title":"Term introduction rule","text":"\\[ \\frac{}{*:1} \\] <p>\"The unit type is equipped with the sole term <code>*:\ud835\udfd9</code>\"</p>"},{"location":"Maths/Type%20Theory/part4/#term-elimination-rule","title":"Term elimination rule","text":"<p>Now that we have discussed dependent types we can talk about the elimination rule more generally. For most (but not all) types <code>A</code> the elimination rule has to specify, given any dependent type <code>B</code> over <code>A</code>, a construction of a term of type <code>\u220fx:A B(x)</code>. </p> <p>To construct a term of type <code>\u220fx:\ud835\udfd9 B(x)</code> is equivalent to proving that <code>B(x)</code> is true for all <code>x:\ud835\udfd9</code>, but since there is only 1 term <code>*:\ud835\udfd9</code> then logically speaking we would only need to prove (contruct a term of) <code>B(*)</code> to obtain a term of <code>\u220fx:\ud835\udfd9 B(x)</code>.    </p> <p>Thus, we come up with the following elimination rule :</p> \\[ \\frac{x:1 \\vdash \\text{B}(x):\\text{Type}}{\\text{rec}_1:\\text{B}(*) \\to \\prod_{x:1} \\text{B}(x)} \\] <p>\"Given a dependent type <code>B</code> over <code>\ud835\udfd9</code>, there is a term <code>rec\u2081</code> of type <code>B(*) \u2192 \u220fx:1 B(x)</code>. Feed <code>rec\u2081</code> a term of <code>B(*)</code> and you will obtain a term of type <code>\u220fx:\ud835\udfd9 B(x)</code> as desired.\"</p>"},{"location":"Maths/Type%20Theory/part4/#computation-rule","title":"Computation rule","text":"\\[ \\frac{x:1 \\vdash \\text{B}(x):\\text{Type}, \\quad p:\\text{B}(*)}{\\text{rec}_1(p,*):=p:\\text{B}(*)} \\] <p>It appears as if <code>rec\u2081</code> is taking in two inputs at once but it is actually doing it one at a time. First, <code>p:B(*)</code> is fed into <code>rec\u2081</code> to create <code>rec\u2081(p) : \u220fx:\ud835\udfd9 B(x)</code>. Then, to <code>rec\u2081(p)</code> we feed <code>*:\ud835\udfd9</code> to create <code>rec\u2081(p)(*):B(*)</code>, which by the rule above simplifies back to <code>p:B(*)</code> again. When a function takes in multiple inputs one at a time as in the above, we simplify the notation like so <code>rec\u2081(p)(*) \u2192 rec\u2081(p,*)</code>, removing unnecessary brackets.</p> <p>The following diagram illustrates this computation rule :</p> <p></p>"},{"location":"Maths/Type%20Theory/part4/#bool-type","title":"Bool Type","text":"<p>You've guessed it, we've created a type with zero terms, a type with one term, now it's time for a type with two terms, the bool type. Let's give it the symbol <code>\ud835\udfda:Type</code> and terms <code>0,1:\ud835\udfda</code>.</p> <p>Type formation and term introduction rules skipped because they should be obvious by now</p>"},{"location":"Maths/Type%20Theory/part4/#term-elimination-rule_1","title":"Term elimination rule","text":"\\[ \\frac{x:2\\vdash \\text{C}(x):\\text{Type}}{\\text{rec}_2:\\text{C}(0)\\to \\text{C}(1)\\to \\prod_{x:2}\\text{C}(x)} \\]"},{"location":"Maths/Type%20Theory/part4/#computation-rule_1","title":"Computation rule","text":"\\[ \\frac{x:2\\vdash \\text{C}(x):\\text{Type}, \\quad c_0:\\text{C}(0), \\quad c_1:\\text{C}(1)}{\\text{rec}_2(c_0,c_1,0):=c_0 : \\text{C}(0), \\quad \\text{rec}_2(c_0,c_1,1):=c_1 : \\text{C}(1)} \\] <p>Alright, let's break this down. A term of <code>\u220fx:\ud835\udfda C(x)</code> is supposed to map <code>0:\ud835\udfda</code> to a term of type <code>C(0)</code> and map <code>1:\ud835\udfda</code> to a term of type <code>C(1)</code>. So to construct a term of <code>\u220fx:\ud835\udfda C(x)</code>, all we need to do is specify the terms that <code>0,1:\ud835\udfda</code> will map to. </p> <p><code>rec_\ud835\udfda</code>, is simply the function that takes in those specifications, i.e, a term of <code>C(0)</code> and a term of <code>C(1)</code>, and outputs a term of <code>\u220fx:\ud835\udfda C(x)</code> based on the provided specification. </p> <p>Suppose <code>x:C(0)</code> and <code>y:C(1)</code> and we feed these into <code>rec_\ud835\udfda</code> to get <code>f := rec(x,y) : \u220fx:\ud835\udfda C(x)</code>. The diagram below illustrates how <code>f</code> behaves.</p> <p></p>"},{"location":"Maths/Type%20Theory/part4/#sum-type","title":"Sum Type","text":"<p>Recall that the dependent sum type <code>\u2211x:A B(x)</code> can be thought of as the sum over all <code>B(x)'s</code> for each <code>x:A</code>. If <code>A:Type</code> consists only of 2 terms, say <code>A := \ud835\udfda</code>, then <code>\u2211x:A B(x)</code> can be thought of as adding two types, <code>B(0)</code> and <code>B(1)</code> together, i.e, </p> <p><pre><code>\u2211x:\ud835\udfda B(x) := B(0) + B(1)\n</code></pre> Let us explore some properties of the type <code>B(0) + B(1)</code>. First is that <code>B(0) \u2192 B(0) + B(1)</code> is inhabited, i.e, we can construct a term of that type : <pre><code>\u03bbx:B(0), (0,x) : B(0) \u2192 B(0) + B(1)\n</code></pre> Similarly, <code>B(1) \u2192 B(0) + B(1)</code> is inhabited. This is similar to how \\(A \\to A \\lor B\\) and likewise \\(B \\to A \\lor B\\) are true in propositional logic. Thus <code>+</code> corresponds to \\(\\lor\\), another connection between type theory and logic!</p> <p>\\(\\neg A\\) from propositional logic corresponds to the type <code>A\u2192\ud835\udfd8</code>. This makes sense because a term <code>p:A\u2192\ud835\udfd8</code> can be thought of as a way of generating a contradiction from <code>A</code> (if we have a term <code>a:A</code> we can apply <code>p:A\u2192\ud835\udfd8</code> to generate <code>p(a):\ud835\udfd8</code>, a contradiction!) Thus, for any <code>A:Type</code> we shall write <code>\u00acA</code> as shorthand for <code>A\u2192\ud835\udfd8</code>.  </p>"},{"location":"Maths/Type%20Theory/part4/#product-type","title":"Product type","text":"<p>We can repeat the same idea to construct, for any types <code>A,B:Type</code>, their product <code>A \u00d7 B:Type</code>. I will leave you to fill in the rest of the details yourself, it is not too difficult to make sense of. (obvious hint: this corresponds to \\(\\land\\) from logic)</p> <p>Notice that <code>\u2211x:A B(x)</code> degenerates to <code>A \u00d7 B</code> if <code>B</code> does not depend on <code>x:A</code><sup>1</sup> </p> <p>There are independent (and equivalent) formulations for the rules of the sum and product type which I encourage you to look through by clicking the respective links</p> <p>Previous Section</p> <p>Next Section</p> <ol> <li> <p>see this \u21a9</p> </li> </ol>"},{"location":"Maths/Type%20Theory/part5/","title":"Part 5 - The Natural Numbers","text":"<p>It is now time to properly define <code>\u2115:Type</code>, the type of natural numbers. We specify the term introduction rule as follows: there is a term <code>0:\u2115</code> and given any <code>n:\u2115</code> we can obtain the \"next\" natural number by applying a successor function <code>s:\u2115\u2192\u2115</code></p>"},{"location":"Maths/Type%20Theory/part5/#term-introduction-rule","title":"Term introduction rule","text":"\\[ \\frac{}{0:\\mathbb{N}} \\quad \\quad \\quad \\frac{n:\\mathbb{N}}{s(n):\\mathbb{N}} \\] <p>With <code>1 := s(0), 2:= s(s(0)), ...</code> and so on...</p>"},{"location":"Maths/Type%20Theory/part5/#term-elimination-rule","title":"Term elimination rule","text":"<p>Given a dependent type <code>n:\u2115 \u22a2 B(n):Type</code>, we need to specify how to construct a term of type <code>\u220fn:\u2115, B(n)</code>. To do so, we just need to apply ideas from natural number induction and translate them into the language of type theory. Doing so gives us the following, we require :</p> <ul> <li>a term of <code>B(0):Type</code></li> <li>given any <code>n:\u2115</code> and <code>p:B(n):Type</code>, a construction of a term of <code>B(s(n)):Type</code>.</li> </ul> <p>in order to construct a term of type <code>\u220fn:\u2115, B(n)</code>. Thus we infer the following elimination rule :</p> \\[ \\frac{n:\u2115 \\vdash \\text{B}(n):\\text{Type}, \\quad b_0:\\text{B}(0), \\quad b_s:\\prod_{n:\\mathbb{N}}\\text{B}(n)\\to \\text{B}(s(n))}{rec_\\mathbb{N}(b_0,b_s):\\prod_{n:\\mathbb{N}}\\text{B}(n)} \\] <p>Alternatively we could have removed <code>b\u2080:B(0)</code> and <code>b\u209b:\u220fn:\u2115, B(n) \u2192 B(s(n))</code> from the top and replaced the bottom with</p> <pre><code>rec_\u2115 : B(0) \u2192 [\u220fn:\u2115, B(n) \u2192 B(s(n))] \u2192 [\u220fn:\u2115, B(n)] \n</code></pre> <p>both versions are equivalent. I just find the top one a bit cleaner.</p> <p>When <code>B(n)</code> does not actually depend on the choice of <code>n:\u2115</code> then we get the simplified version :</p> \\[ \\frac{\\text{B}:\\text{Type}, \\quad b_0:\\text{B}, \\quad b_s:\\mathbb{N}\\to \\text{B}\\to \\text{B}}{rec_\\mathbb{N}(b_0,b_s):\\mathbb{N}\\to \\text{B}} \\] <p>which is useful for defining operations on <code>\u2115</code>, as an example we show how to define a function <code>double:\u2115\u2192\u2115</code> that doubles numbers. But first, we introduce the computation rules.</p>"},{"location":"Maths/Type%20Theory/part5/#computation-rules","title":"Computation rules","text":"\\[ \\frac{n:\u2115 \\vdash \\text{B}(n):\\text{Type}, \\quad b_0:\\text{B}(0), \\quad b_s:\\prod_{n:\\mathbb{N}}\\text{B}(n)\\to \\text{B}(s(n)), \\quad n:\\mathbb{N}}{rec_\\mathbb{N}(b_0,b_s,0):=b_0:\\text{B}(0), \\quad rec_\\mathbb{N}(b_0,b_s,s(n)):=b_s(n, rec_\\mathbb{N}(b_0,b_s,n)):\\text{B}(s(n))} \\] <p>here is a diagram to illustrate (we simplify <code>rec_\u2115(b\u2080,b\u209b) := rec</code>) :</p> <p></p>"},{"location":"Maths/Type%20Theory/part5/#doubling-function","title":"Doubling function","text":"<p>A doubling function on the natural numbers is a function <code>Double:\u2115\u2192\u2115</code> saatisfying <code>Double(n) := 2n</code> for all <code>n:\u2115</code>. Such a function can be constructed by using the simplified elimination rule on <code>\u2115</code> with <code>B := \u2115</code> and supplying a suitable <code>b\u2080:\u2115</code> and <code>b\u209b:\u2115\u2192\u2115\u2192\u2115</code> so that <code>rec_\u2115(b\u2080,b\u209b) := Double</code>. </p> <p>Figuring out how to select a suitable <code>b\u2080</code> and <code>b\u209b</code> is easy. We just have to apply the computation rules and fill in the blanks. Suppose we have been given suitable <code>b\u2080</code> and <code>b\u209b</code> but without knowledge of their values, then the first computation rule gives :</p> <pre><code>rec_\u2115(b\u2080,b\u209b,0) := Double(0) := b\u2080\n</code></pre> <p>Obviously we want <code>Double(0) := 0</code> so we must select <code>b\u2080 := 0</code>. Figuring out <code>b\u209b</code> is a bit harder. Given any <code>n:\u2115</code>, the second computation rule states that</p> <p><pre><code>rec_\u2115(b\u2080,b\u209b,s(n)) := b\u209b(n,rec_\u2115(b\u2080,b\u209b,n))\n  --- simplifies to\nDouble(s(n)) := b\u209b(n,Double(n))\n</code></pre> But notice that for any <code>n:\u2115</code> <pre><code>Double(s(n)) := Double(n+1)\n             := 2n + 2\n             := s(s(Double(n)))\n  --- thus\nb\u209b(n,Double(n)) := s(s(Double(n)))\n</code></pre> So it is clear now that we must select <code>b\u209b := \u03bbn:\u2115,\u03bbm:\u2115, s(s(m))</code>. Notice that the first input of <code>b\u209b</code> is irrelevant to the computation but it must be included anyway to ensure that <code>b\u209b</code> has the type <code>\u2115\u2192\u2115\u2192\u2115</code> as needed, lest we have <code>b\u209b:\u2115\u2192\u2115</code>.</p> <p>Hang on! <code>Double(s(n)) := s(s(Double(n)))</code> is not something we can determine with our type system just yet.. we haven't even defined <code>+</code> in our type system.</p> <p>That's right, we don't know that <code>Double(s(n)) := s(s(Double(n)))</code> is true, we just went ahead of ourselves and did some pretend arithmetic.. but that is to figure out how we need <code>Double</code> to behave recursively, i.e, how to define <code>Double(s(n))</code> in terms of <code>Double(n)</code>. </p> <p>Once done, we select <code>b\u209b</code> specifically to ensure that <code>Double(s(n)) := s(s(Double(n)))</code>, the recursive property we want true, holds by virtue of the computation rule.</p> <p>Here is the doubling function in full, constructed from scratch :</p> <pre><code>Double := rec_\u2115(0,[\u03bbn:\u2115,\u03bbm:\u2115, s(s(m))])\n</code></pre> <p>As an exercise, try to verify that <code>Double(3) := 6</code> by unfolding the definitions and repeating the computation rules.</p> <p>We can construct many other functions by following the same process. As another example, we will construct the addition function <code>+:\u2115\u2192\u2115\u2192\u2115</code>.</p>"},{"location":"Maths/Type%20Theory/part5/#addition-function","title":"Addition function","text":"<p>We do the same thing all over again but with <code>B := \u2115 \u2192 \u2115</code> this time. This will be a lot more difficult, but the principle is the same. First, notice that <pre><code>rec_\u2115(b\u2080,b\u209b) := +  --- hence\nrec_\u2115(b\u2080,b\u209b,0) := + 0\n</code></pre> Wait a moment! what the hell is <code>+ 0</code> ??? How does this make sense? I acknowledge that this is all a bit unconventional but I promise it makes sense, give me a chance to explain.</p> <p>Let's ask the simple question first : What is the type of <code>+ 0</code>? Well, given that <code>+:\u2115\u2192\u2115\u2192\u2115</code> and <code>0:\u2115</code>, we must have <code>+ 0:\u2115\u2192\u2115</code>. This is simply the elimination rule for the function type. Moreover, one of the computation rules state that :</p> <pre><code>+ := \u03bbn:\u2115,\u03bbm:\u2115, +(n,m)\n</code></pre> <p>where <code>+(n,m) := n + m</code>, this is simply writing <code>+</code> with the Polish notation which does nothing but to emphasize that <code>+</code> is indeed a function. This is helpful because most education systems present and teach <code>+</code> as an operator, and the infix notation <code>n + m</code> makes it harder to make the connection that <code>+</code> can be thought of as a function. </p> <p>It is not that <code>+</code> being an operator is untrue, but rather that \"operator \u2286 function\" and we wish to look at things from a broader perspective. </p> <p>Going back on topic, this means that</p> <pre><code>+ 0 := \u03bbm:\u2115, +(0,m) := \u03bbm:\u2115, m\n</code></pre> <p>So it is clear that <code>+ 0 := Id_\u2115</code> where <code>Id_\u2115:\u2115\u2192\u2115</code> is the identity function (leaves output unchanged) on <code>\u2115</code>. Hence <code>b\u2080 := Id_\u2115</code>.</p> <p>To tackle defining <code>b\u209b</code> we first introduce function composition :</p> <p>Definition. Given types <code>A, B, C</code> and <code>f:A\u2192B, g:B\u2192C</code> we shall write <code>g\u2218f:A\u2192C</code> as short hand for the lambda abstraction <code>\u03bba:A, g(f(a))</code>. </p> <p>Now notice that for any given <code>n:\u2115</code> the second computation rule gives the equality : <pre><code>+ s(n) := b\u209b(n,+ n)\n</code></pre> but notice that <pre><code>+ s(n) := \u03bbm:\u2115, s(n) + m\n       := \u03bbm:\u2115, n + s(m)\n       := [\u03bbm:\u2115, n + m] \u2218 s\n       := (+ n) \u2218 s\n</code></pre> thus, we define <code>b\u209b := \u03bbn:\u2115, \u03bbf:\u2115\u2192\u2115, f\u2218s</code>. </p> <p>Again, the first input is useless, it actually only becomes useful when we apply the original (actually dependent) version of the elimination rule for <code>\u2115</code>. </p> <p>You can verify that indeed for these choices of <code>b\u2080</code> and <code>b\u209b</code>, a function that models addition is constructed. Here is how we would compute <code>2+1</code> for example</p> <pre><code>2 + 1 := (+ 2) (1)\n      := (+ 1) \u2218 s (1)\n      := (+ 1) (2)\n      := (+ 0) \u2218 s (2)\n      := (+ 0) (3)\n      := 3\n</code></pre>"},{"location":"Maths/Type%20Theory/part6/","title":"Part 6 - Universes","text":"<p>At the very beginning we mentioned that type theory is nothing more than a 2-level system. That was a lie. Things start to get complicated here (heck, even I'm confused) so I stalled this discussion, hiding you guys away from the ugly truth.</p> <p>There is a culmulative hierarchy of universes</p> \\[ \\mathcal{U}_0:\\mathcal{U}_1:\\mathcal{U}_2:\\cdots \\] <p>and what we formally mean when we say <code>A:Type</code> is that <code>A:U_i</code> for some <code>i:\u2115</code>. </p> <p>In particular, every universe <code>U_i</code> is a type since <code>U_i:U_(i+1)</code>. This idea is very very important</p> <p>We also have</p> <ul> <li>Culmulativity: If <code>A:U_i</code> then <code>A:U_(i+1)</code></li> <li>Closure: If <code>A:U_i</code> and <code>B:U_v</code> then <code>A+B, A\u2192B, etc..</code> are in <code>U_(max i v)</code><ul> <li>more importantly <code>U_(max i v)</code> is the lowest universe level that contains these types</li> </ul> </li> </ul> <p>We usually avoid mentioning the level of the universe explicitly, simply writing <code>U</code>, and assume that the levels can be assigned in a consistent way. For example, although confusing, we can write <code>U:U</code>. To interpret <code>U:U</code> we'll need to assign the universe levels. For example, level <code>0</code> to the first instance of <code>U</code> and <code>1</code> to the second instance, giving <code>U_0:U_1</code>. Of course, there are many other valid interpretations of <code>U:U</code> based on alternative level assignments. We can think of any expression involving (the ambiguous) <code>U</code> as a superposition of all valid interpretations (universe level assignments) of that expression.</p> <p>We use this notation in cases where having the explicit universe level is not relevant, which is mostly the case anyway</p> <p>Having universes means that everything now has a type. Previously, if <code>a:A</code> then type of <code>a</code> is <code>A</code> but, going one step higher, there is no answer to the question: \"what is the type of <code>A</code>?\". With universes, we know that since <code>A:Type</code> we have <code>A:U_i</code> for some <code>i:\u2115</code> so the type of <code>A</code> is <code>U_i</code>. </p> <p>But also valid is <code>A:U_(i+1)</code>, meaning <code>U_(i+1)</code> is another answer to \"what is the type of <code>A</code>?\". So with universes the type of an object is no longer unique<sup>1</sup>.</p>"},{"location":"Maths/Type%20Theory/part6/#why","title":"WHY????","text":"<p>Although this does make our system a lot more complicated to study, there are some benefits. First, it allows us to formalize the notion of a dependent type. </p> <p>Definition. Let <code>A:Type</code>, a dependent type on <code>A</code> is a term of type <code>A\u2192U</code>.</p> <p>Notice that since no explicit universe level is mentioned, what we mean by a term of type <code>A\u2192U</code> is a term whose type comes from the following list:</p> <p><pre><code>A\u2192U_0,  A\u2192U_1,  A\u2192U_2,  ...\n</code></pre> In particular, <code>B:A\u2192U_99, C:A\u2192U_122, D:A\u2192U_0, etc..</code> are all dependent types on <code>A</code>. Remember, we can think of the expression <code>A\u2192U</code> as a superposition ranging across all universe levels.</p> <p>Hang on! Before we can make that definition we need to make sure that <code>A\u2192U</code> is a type. The formation rule for functions is given by</p> \\[ \\frac{\\text{A:Type}, \\quad \\text{B:Type}}{\\text{A}\\to \\text{B : Type}} \\] <p>but with universes we have</p> \\[ \\frac{\\text{A: }\\mathcal{U}, \\quad \\text{B: }\\mathcal{U}}{\\text{A}\\to \\text{B: }\\mathcal{U}} \\] <p>There are many ways to interpret (assign universe levels to) the above rule, for example :</p> \\[ \\frac{\\text{A: }\\mathcal{U}_2, \\quad \\text{B: }\\mathcal{U}_2}{\\text{A}\\to \\text{B: }\\mathcal{U}_2} \\] <p>Is a valid interpretation; or more generally for any <code>i:\u2115</code> we have,</p> \\[ \\frac{\\text{A: }\\mathcal{U}_i, \\quad \\text{B: }\\mathcal{U}_i}{\\text{A}\\to \\text{B: }\\mathcal{U}_i} \\] <p>This is the most common interpretation and we will adopt it as the default</p> <p>But we cannot have the following interpretation,</p> \\[ \\frac{\\text{A: }\\mathcal{U}_2, \\quad \\text{B: }\\mathcal{U}_2}{\\text{A}\\to \\text{B: }\\mathcal{U}_1} \\] <p>because that would break closure. Another valid interpretation is</p> \\[ \\frac{\\text{A: }\\mathcal{U}_i, \\quad \\text{B: }\\mathcal{U}_j}{\\text{A}\\to \\text{B: }\\mathcal{U}_{(\\text{max} \\ i \\ j)}}, \\quad i,j:\\mathbb{N}  \\] <p>If an interpretation is valid, it gives rise to a valid type formation rule. Thus, we can think of it as if there are many different copies (versions) of the type formation rule and we may use whichever one is appropriate. </p> <p>Now setting <code>B:=U</code> gives  $$ \\frac{\\text{A: }\\mathcal{U}_i, \\quad \\mathcal{U}:\\mathcal{U}_i}{\\text{A}\\to \\mathcal{U}:\\mathcal{U}_i}, \\quad i:\\mathbb{N} $$</p> <p>Where, to make this valid it suffices to select a large enough <code>i</code> so that both <code>A:U_i</code> and <code>U:U_i</code>. For example if <code>A:Type</code> lives in universe level 42 and we want to form <code>A \u2192 U_73</code>, then we can use the <code>i=99</code> version of the type formation rule,</p> \\[ \\frac{\\text{A: }\\mathcal{U}_{99}, \\quad \\mathcal{U}_{73}:\\mathcal{U}_{99}}{\\text{A}\\to \\mathcal{U}_{73}:\\mathcal{U}_{99}} \\] <p>Obtaining the statement <code>A\u2192U_73:U_99</code> which confirms that <code>A\u2192U_73</code> is a type (because it lives in some universe) Of course there is nothing special about level 99. Any level above 73 will do. For example, we can also obtain the statement <code>A\u2192U_73:U_74</code>, but we don't care. The end result stays the same regardless: <code>A\u2192U_73</code> lives in some universe, therefore <code>A\u2192U_73</code> is a type.</p> <p>Similarly, there is nothing special about <code>U_73</code> and we can repeat this argument for any universe <code>U</code>. Thus <code>A\u2192U</code> is indeed a type. Check here for more persepctives on this matter.</p>"},{"location":"Maths/Type%20Theory/part6/#polymorphic-identity-function","title":"Polymorphic Identity Function","text":"<p>If <code>A:Type</code> then an identity function on <code>A</code> is the function <code>Id_A:A\u2192A</code> given by the lambda abstraction <code>\u03bba:A, a</code>. For example, <code>Id_\u2115(5):=5, etc ...</code> But this means that each type needs to have its own identity function. With universes we can have a global identity function. A function <code>Id : \u220fC:U C\u2192C</code> which takes a type <code>C:U</code> as input and outputs a term of type <code>C\u2192C</code>, that term being the identity function on <code>C</code>. For example, if we want an identity function on <code>\u2115</code> we simply feed <code>\u2115</code> into <code>Id</code> to get what we want.</p> <p>First, let us show that <code>\u220fC:U C\u2192C</code> is indeed a type. The dependent product formation rule was once</p> \\[ \\frac{\\text{A}:\\text{Type}, \\quad x:\\text{A} \u22a2 \\text{B}(x):\\text{Type}}{\\prod_{x:\\text{A}}\\text{B}(x):\\text{Type}} \\] <p>but with universes,</p> \\[ \\frac{\\text{A}:\\mathcal{U}_i, \\quad \\text{B}:\\text{A}\\to \\mathcal{U}_i}{\\prod_{x:\\text{A}}\\text{B}(x):\\mathcal{U}_i}, \\quad i:\\mathbb{N} \\] <p>A reminder: this is just one of the many forms that the dependent product formation rule can take</p> <p>To create the type we want, we set <code>A:=U</code> and <code>B:=\u03bbC:U, C\u2192C</code>, meanwhile assuming a suitable <code>i</code> (which is always possible so we won't blab on about this anymore), giving</p> \\[ \\frac{\\mathcal{U}:\\mathcal{U}_i, \\quad \\lambda_{C:\\mathcal{U}},C\\to C:\\mathcal{U}\\to \\mathcal{U}_i}{\\prod_{C:\\mathcal{U}}C\\to C:\\mathcal{U}_i} \\] <p>Thus <code>\u220fC:U C\u2192C</code> is indeed a type and we can define the term  <pre><code>Id := \u03bbC:U, (\u03bbx:C, x) : \u220fC:U C\u2192C\n</code></pre> the polymorphic identity function. What we mean by polymorphic is that <code>Id:\u220fC:U C\u2192C</code> is dynamic to whatever input it recieves. If <code>A:Type</code> with universe level 23 is fed into it, then <code>Id:\u220fC:U C\u2192C</code> (whose type is a superposition/polymorphic) adopts a suitable form to accomodate the incoming <code>A:Type</code>, say <code>Id:\u220fC:U_24 C\u2192C</code> or <code>Id:\u220fC:U_99 C\u2192C</code>. This means that <code>Id</code> can accept a type from any universe level. </p> <p>I will say polymorphic now instead of superposition as it is more mathematically accurate</p>"},{"location":"Maths/Type%20Theory/part6/#some-helpful-links","title":"Some helpful links","text":"<ul> <li> <p>https://cs.stackexchange.com/questions/13285/universes-in-dependent-type-theory</p> </li> <li> <p>https://leanprover.github.io/theorem_proving_in_lean4/dependent_type_theory.html</p> </li> <li> <p>https://leanprover.github.io/functional_programming_in_lean/functor-applicative-monad/universes.html</p> </li> <li> <p>https://www.reddit.com/r/ProgrammingLanguages/comments/tjev87/type_theorys_type_universe_what_is_the_type_of/</p> </li> </ul> <ol> <li> <p>there is a way to fix this which I will not implement, and that is to introduce transport functions between universes. See here.\u00a0\u21a9</p> </li> </ol>"},{"location":"Maths/Type%20Theory/part7/","title":"Part 7 - Propositions","text":"<p>Across our type theory journey I've been showcasing some connections between type theory and logic. For example: <code>\u220f</code> can be seen as \\(\\forall\\), <code>\u2211</code> as \\(\\exists\\), <code>+</code> as \\(\\lor\\) and so on. In particular, we view types as propositions and propositions as types. This, I feel, is a very beautiful (and more importantly, powerful) interpretation. </p> <p>Unfortunately, things don't always work out perfectly and the proposition as types interpretation has some flaws which I've thus far hidden. We shall discuss them now and present a solution.</p>"},{"location":"Maths/Type%20Theory/part7/#the-first-flaw","title":"The first flaw","text":"<p>If we want to do classical mathematics, it will be helpful to have something akin to the law of excluded middle (LEM). This is an axiom stating that for any proposition \\(P\\) we have \\(P \\lor \\neg P\\). Translating into type theory, this amounts to the existence of a term with the type</p> <pre><code>\u220fP:U (P + \u00acP),      recall \u00acP := P \u2192 \ud835\udfd8\n</code></pre> <p>So to introduce LEM into our type system, we just need to make it an axiom that there exists a term of the type above. Problem solved... or not because for reasons beyond my capabilities of understanding, asserting such a term makes the system inconsistent and creates a contradiction.</p>"},{"location":"Maths/Type%20Theory/part7/#the-second-flaw","title":"The second flaw","text":"<p>We want proof irrelevance, what that means is there should be no difference between two proofs <code>p,q:P</code> of the same proposition <code>P:Type</code>, i.e, we want <code>p=q</code>, obviously not all types satisfy this condition. </p> <p>In constructive mathematics, proofs can be different, for example a proof of <code>\u2211x:\u2115, x&gt;0</code> can be either <code>1:\u2115</code> paired with a proof <code>p1:1&gt;0</code>, or it can be <code>2:\u2115</code> paired with a proof <code>p2:2&gt;0</code>. In classical mathematics this sort of detail is not important. We can even, if we want to, provide a proof that there exists an <code>x:\u2115</code> such that <code>x&gt;0</code> without supplying an <code>x:\u2115</code> and a proof of <code>x&gt;0</code>. Of course, what I'm implying is the use of proof by contradiction.</p> <p>Alas, as it stands right now, a term of <code>\u2211x:\u2115, x&gt;0</code> cannot be constructed via proof by contradiction. Let's imagine we try to do exactly just that. First, we assume the opposite, i.e, that we have a proof <code>p:\u00ac(\u2211x:\u2115, x&gt;0)</code> and see if we can generate a contradiction (a term of <code>\ud835\udfd8</code>) from <code>p</code>. This way a proof by contradiction amounts to constructing a term with type</p> <pre><code>\u00ac(\u2211x:\u2115, x&gt;0) \u2192 \ud835\udfd8 := \u00ac\u00ac(\u2211x:\u2115, x&gt;0)\n</code></pre> <p>but coming up with a term of <code>\u00ac\u00ac(\u2211x:\u2115, x&gt;0)</code> dosen't necessarily mean we have a term of <code>\u2211x:\u2115, x&gt;0</code> unless there is a function</p> <pre><code>f : \u00ac\u00ac(\u2211x:\u2115, x&gt;0) \u2192 \u2211x:\u2115, x&gt;0\n</code></pre> <p>(corresponding to some sort of double negation elimination rule) which is impossible to construct without LEM (and remember we can't assume LEM). </p> <p>This is not to say that the type <code>\u2211x:\u2115, x&gt;0</code> (and other similar types) is not a valid representation of the proposition \"there exists an <code>x:\u2115</code> such that <code>x&gt;0</code>\", but rather <code>\u2211x:\u2115, x&gt;0</code> represents a \"constructive\" version of that proposition, i.e, we cannot construct a term of this type via non-constructive methods (proof by contradiction)</p> <p>It is possible to create a \"classical\" version of <code>\u2211x:\u2115, x&gt;0</code> and this is what we will be touching upon.</p>"},{"location":"Maths/Type%20Theory/part7/#the-solution","title":"The solution","text":"<p>Definition. Given <code>A:Type</code>, define</p> \\[ \\text{IsProp}(\\text{A}):=\\prod_{x,y:\\text{A}}x=y \\] <p>we say that <code>A:Type</code> is an h-proposition if <code>IsProp(A)</code> is inhabited. </p> <p>The definition of <code>IsProp</code> implies that <code>x=y</code> is a type (which shouldn't be a surprise), we'll formally define equality types shortly. </p> <p>If <code>A:Type</code> is an h-proposition, then we know that any two terms of <code>A</code> are equal. This automatically gives us proof irrelevance. Another way to see this is that <code>A</code> has at most one term. </p> <p>It turns out that if <code>A:Type</code> is an h-proposition, then LEM works on <code>A</code>, i.e, we can assume that the type</p> <pre><code>\u220fA:U, IsProp(A) \u2192 (A + \u00acA)\n</code></pre> <p>is inhabited without any problems. So, as for the solution... what if instead of having a correspondence between propositions and types, we have a correspondence between propositions and some types. By some we of course mean types that are h-propositions. </p>"},{"location":"Maths/Type%20Theory/part7/#the-equality-type","title":"The equality type","text":"<p>The type formation rule is as you would expect: </p> \\[ \\frac{\\text{A}:\\mathcal{U}, \\quad a,b:\\text{A}}{a=b:\\mathcal{U}} \\] <p>In particular if <code>a:A</code> and <code>b:B</code> (with distinct <code>A</code> and <code>B</code>) then <code>a=b</code> is nonsense. We can only form an equality relation between two terms of the same type.</p> <p>The term introduction rule is given by:</p> \\[ \\frac{\\text{A}:\\mathcal{U}}{ \\text{refl}:\\prod_{a:A}(a=a)} \\] <p>This means that for any <code>a:A</code> there is a proof of <code>a=a</code>, namely <code>refl(a):a=a</code>.</p> <p>The term elimination rule (sometimes called the J-rule) is as follows:</p> <p>Let <code>A:U</code>. Then, given a dependent type</p> \\[  C:\\prod_{x,y:\\text{A}}\\left[(x=y)\\to \\mathcal{U}\\right] \\] <p>and a function</p> \\[ c:\\prod_{x:\\text{A}}C(x,x,\\text{refl}(x)) \\] <p>there is a function</p> \\[ f:\\prod_{x,y:\\text{A}}\\prod_{p:x=y}C(x,y,p) \\] <p>The computation rule is that</p> \\[ x:\\text{A} \\vdash f(x,x,\\text{refl}(x)):= c(x) \\] <p>We called <code>C</code> a dependent type, though it isn't in the traditional sense since it accepts three inputs (instead of one) before outputting a type. The first two inputs are terms of <code>A</code> and the third input is a term of a path (equality) between those terms. I.e, given <code>x,y:A</code> and <code>p:x=y</code> we have <code>C(x,y,p):U</code>. </p> <p>We shall expand our worldview to include/consider instances like the above whenever we mention or deal with dependent types.</p> <p>Obtaining a term :</p> \\[ f:\\prod_{x,y:\\text{A}}\\prod_{p:x=y}C(x,y,p) \\] <p>is equivalent to showing that <code>C(x,y,p)</code> is inhabited for whatever <code>x,y:A</code> and <code>p:x=y</code>. Indeed, given the terms <code>x,y,p</code> one just has to feed these into <code>f</code> to exhibit a term of <code>C(x,y,p)</code>, i.e, </p> <pre><code>x,y:A, p:x=y, \u22a2 f(x,y,p):C(x,y,p)\n</code></pre> <p>The elimination rule states that such an <code>f</code> can be obtained by exhibiting a term of type</p> \\[ \\prod_{x:\\text{A}}C(x,x,\\text{refl}(x)) \\]"},{"location":"Maths/Type%20Theory/part7/#judgemental-equality","title":"Judgemental equality","text":"<p>You may have noticed that we have introduced equalities many times before, specifically when specifying a computation rule. In those instances the equality is given with the symbol <code>:=</code> to distinguish it from the \"typal\" notion of equality we defined above.</p> <p>How exactly these two notions of equality differ is not something that I understand completely, but here is what I know so far:</p> <ul> <li> <p>Judgemental equality is a stronger (meta-theoretic) notion of equality than typal equality. </p> </li> <li> <p>How to use/apply: </p> <ul> <li>A judgemental equality <code>a:=b</code> allows us the ability to swap any instance of <code>a</code> into <code>b</code> (and vice versa) in any formula.</li> <li>A term <code>p:a=b</code> of a typal equality is made use of by applying the term elimination (J) rule.</li> </ul> </li> </ul> <p>See here for more info.</p>"},{"location":"Maths/Type%20Theory/part7/#example-1","title":"Example 1","text":"<p>To get a hang of the J-rule, let's use it to prove that equality is symmetric, i.e, given <code>a,b:A</code> and <code>p:a=b</code> the type <code>b=a</code> is inhabited as well. </p> <p>Proving the above statement is equivalent to finding a term with type</p> \\[ \\prod_{a,b:\\text{A}}(a=b) \\to (b=a) \\tag{1}\\] <p>If we define</p> \\[ C := \\lambda_{a:\\text{A}}\\lambda_{b:\\text{A}}\\lambda_{p:a=b}, \\ b=a  \\] <p>then (1) can be rewritten as</p> \\[ \\prod_{a,b:\\text{A}}\\prod_{p:a=b} C(a,b,p) \\] <p>According to the elimination rule, to find a term with the above type, it suffices to exhibit a term with the type</p> \\[ \\prod_{x:\\text{A}} C(x,x,\\text{refl}(x)) := \\prod_{x:\\text{A}} x=x\\] <p>According to the term introduction rule, we know that there is a function called <code>refl</code> with the type <code>\u220fx:A, x=x</code>, so we are done.</p> <p>Try to prove the transitive property of equality</p> \\[ \\prod_{x,y,z:\\text{A}}(x=y)\\to (y=z) \\to (x=z) \\] <p>check page 22 of this document if you get stuck. The whole thing is a good read regardless if you want to learn more about identity types.</p>"},{"location":"Maths/Type%20Theory/part7/#example-2-transport","title":"Example 2 (transport)","text":"<p>Let <code>A:U</code>. If <code>P:A\u2192U</code> is a dependent type on <code>A</code> then given <code>x,y:A</code> and <code>p:x=y</code> there exists a function <code>f:P(x)\u2192P(y)</code>. This statement is known as transport and it can be proved starting from the J-rule. </p> <p>We can think of equality as a path, i.e, <code>p:x=y</code> is a path from <code>x:A</code> to <code>y:A</code>. So the principle of transport can be stated as:</p> <pre><code>if there is a path from `x:A` to `y:A` then terms can be\ntransported (via a function) back and forth between \n`P(x)` and `P(y)`.\n</code></pre> <p>we say back and forth because a path from <code>x:A</code> to <code>y:A</code> can also be considered as a path from <code>y:A</code> to <code>x:A</code> (symmetric property of equality) from which we can generate a backwards transport function <code>g:P(y)\u2192P(x)</code></p> <p>The following diagram illustrates the principle of transport:</p> <p></p> <p>The principle of transport can be expressed by the type</p> \\[ \\prod_{x,y:\\text{A}}\\prod_{p:x=y}\\prod_{\\text{P}:\\text{A}\\to\\mathcal{U}} (P(x)\\to P(y)) \\tag{2} \\] <p>We define</p> \\[ C := \\lambda_{x:\\text{A}}\\lambda_{y:\\text{A}}\\lambda_{p:x=y}, \\ \\prod_{\\text{P}:\\text{A}\\to \\mathcal{U}}(P(x)\\to P(y)) \\] <p>then (2) can be rewritten as</p> \\[ \\prod_{x,y:\\text{A}}\\prod_{p:x=y} C(x,y,p) \\] <p>to find a term of the type above, it suffices to exhibit an inhabitant of :</p> \\[ \\prod_{x:\\text{A}}C(x,x,\\text{refl}(x)) := \\prod_{x:\\text{A}}\\prod_{\\text{P}:\\text{A}\\to\\mathcal{U}}(P(x)\\to P(x)) \\] <p>We do so by defining</p> \\[ c := \\lambda_{x:\\text{A}}, \\lambda_{\\text{P}:\\text{A}\\to \\mathcal{U}}, \\ \\text{Id}(\\text{P}(x)) \\] <p>(we defined the function <code>Id</code> in Part 6), this concludes the proof.</p> <p>We call the inhabitant of (2) <code>Transport</code>. Notice that by the computation rule, we must have</p> <pre><code>x:A, P:A\u2192U \u22a2 Transport(x,x,refl(x),P) := c(x,P) := Id(P(x)) \n</code></pre>"},{"location":"Maths/Type%20Theory/part7/#using-transport-to-prove-example-1","title":"Using <code>Transport</code> to prove Example 1","text":"<p>Here is a rough proof sketch, suppose <code>a,b:A</code> and <code>p:a=b</code>, define a dependent type <code>B</code> on <code>A</code> with <code>B:=\u03bbx:A, x=a</code> then by transport, there exists a function <code>F:B(a)\u2192B(b)</code>, feed <code>refl</code> into <code>F</code> and we get <code>F(refl):b=a</code> as needed. Below is a diagram</p> <p></p> <p>The full proof term for <code>\u220fa,b:A,(a=b)\u2192(b=a)</code> is</p> <pre><code>\u03bba,b:A, \u03bbp:a=b, [Transport(a,b,p,(\u03bbx:A, x=a))](refl)\n</code></pre> <p>With this same approach, try proving the transitive property of equality, it is much easier and satisfying to do it with the help of transport.</p>"},{"location":"Maths/Type%20Theory/part7/#a-universe-of-propositions","title":"A Universe of Propositions","text":"<p>It will be helpful if there exists a universe, let's call it <code>Prop</code>, such that every single h-proposition type lives in <code>Prop</code>. That way, instead of writing</p> <pre><code>\u220fA:U, IsProp(A) \u2192 (A + \u00acA)\n</code></pre> <p>we can simply write</p> <pre><code>\u220fA:Prop, A + \u00acA\n</code></pre> <p>The canonical inhabitant of the above type, by the way, we'll call <code>LEM</code> (short for law of excluded middle).  </p> <p>Another useful thing with the <code>Prop</code> universe is that a proposition \\(P\\) in type theory terms simply means <code>P:Prop</code> and likewise a predicate \\(P\\) on \\(A\\) means <code>P:A\u2192Prop</code>.</p> <p>It's possible to explicitly construct the universe <code>Prop</code> but I'll leave the explanation out for brevity (for those interested, click here). I should also say that <code>Prop</code> sits at the bottom of the hierarchy of universes, i.e,</p> <pre><code>Prop : U_0 : U_1 : U_2 : ...\n</code></pre>"},{"location":"Maths/Type%20Theory/part7/#extensional-and-observational-type-theory","title":"Extensional and Observational Type Theory","text":"<p>Extensional type theory is a particular flavour of type theory in which a term <code>p:a=b</code> of an equality type produces a judgemental equality. This is given by the following rule :</p> \\[ \\frac{ p:a=b}{a:=b} \\] <p>This simplifies our type theory by a ton. For example, the J-rule is now redundant since we can (instead) \"upgrade\" typal equality into a judgemental equality, then this allows us to freely swap <code>a</code> for <code>b</code> or vice versa in any formula.</p> <p>Another consequence of extensional type theory is that equality types are propositional, that is, for every <code>A:Type</code> and <code>a,b:A</code>, the type <code>a=b</code> is an h-proposition, i.e, we can reformat the equality type formation rule into</p> \\[ \\frac{\\text{A}:\\mathcal{U}, \\quad a,b:\\text{A}}{a=b:\\text{Prop}} \\] <p>Just to reiterate, the above is not a fact but rather an assumption about the type system. I will choose to follow this assumption at times just because it makes things a lot easier. Though there are drawbacks</p> <p>There is also something called observational type theory which is also helpful. From what I can understand, equality is defined on types on a case by case basis. Equality between functions for example, is given by the following rule :</p> \\[ \\frac{f,g:A\\to B, \\ p:\\prod_{x:\\text{A}}, f(x)=g(x)}{q:f=g}\\] <p>This rule is called functional extensionality. It cannot be proved, either we accept it as an axiom, or we can adopt observational type theory where this rule (and many other extensionality rules for different types) are included in the package already.</p> <p>The observational equality (extensional) rule for <code>Prop</code> is known as propositional extensionality</p> \\[\\frac{\\text{A, B}:\\text{Prop}, \\quad f:\\text{A}\\to \\text{B}, \\quad g:\\text{B}\\to \\text{A}}{p:\\text{A}=\\text{B}}\\] <p>This should make sense as in propositional logic, two propositions <code>A</code> and <code>B</code> are equivalent if they imply each other. </p>"},{"location":"Maths/Type%20Theory/part7/#1-is-an-h-proposition","title":"\ud835\udfd9 is an h-proposition","text":"<p><code>\ud835\udfd9:Type</code> is clearly an h-proposition. Can we prove it though? To do so we need to exhibit an inhabitant of the type</p> \\[ \\text{IsProp}(1) := \\prod_{x:1}\\prod_{y:1}, \\ x=y \\tag{3} \\] <p>If we define the dependent type <code>B:\ud835\udfd9\u2192U</code> with</p> \\[ \\text{B} := \\lambda_{x:1}, \\ \\left[\\prod_{y:1}, \\ x=y\\right] \\] <p>then (1) simplifies to</p> \\[ \\prod_{x:1}, \\  \\text{B(x)} \\tag{4}\\] <p>To find an inhabitant of the type (4), it suffices by the elimination/induction rule for <code>\ud835\udfd9:Type</code>, to find an inhabitant of type</p> \\[ \\text{B}(\\star) := \\prod_{y:1}, \\ \\star=y \\] <p>Repeating the induction once again, our problem simplifies to finding an inhabitant of <code>\u22c6=\u22c6</code>. Of course, there is <code>refl(\u22c6):\u22c6=\u22c6</code> so we are done here.</p> <p>or sometimes we write <code>refl</code> instead, skipping the variable since it is clear enough from context</p> <p>This completes our proof that <code>IsProp(\ud835\udfd9)</code> is inhabited. Obviously it is great that we have <code>\ud835\udfd9:Prop</code> since we can have <code>\ud835\udfd9</code> represent the <code>TRUE</code> proposition, and of course that we have <code>\ud835\udfd8</code> for <code>FALSE</code> as well.</p> <p>Try to prove that <code>IsProp(\ud835\udfd8)</code> is inhabited as well</p>"},{"location":"Maths/Type%20Theory/part7/#operations-on-prop","title":"Operations on Prop","text":"<p>In propositional logic, if we have propositions \\(P\\) and \\(Q\\) then \\(P\\lor Q, P\\to Q, \\cdots\\) are all propositions as well. If we translate this to type theory will this still hold? That is to say, given <code>P,Q:Prop</code> are <code>P+Q, P\u2192Q, ...</code> h-propositions as well?</p> <p>The answer is... sometimes. For example the <code>\u2192</code> operation is closed under <code>Prop</code>, meaning</p> \\[ \\prod_{P,Q:\\text{Prop}} \\text{IsProp}(P\u2192Q) \\] <p>can be proved (has an inhabitant). However, the same is not true for the <code>+</code> operation. For example, <code>\ud835\udfd9+\ud835\udfd9:Type</code> is not an h-proposition (despite <code>\ud835\udfd9</code> being an h-proposition). It has terms <code>inl(\u22c6),inr(\u22c6):\ud835\udfd9+\ud835\udfd9</code> </p> <p>check the rules for the sum type if you haven't already.</p> <p>but we have <code>inl(\u22c6)\u2260inr(\u22c6)</code>. How can we prove this? Well of course by exhibiting an inhabitant of <code>inl(\u22c6)=inr(\u22c6) \u2192 \ud835\udfd8</code>. This proof will utilize the principle of transport, so first let us define a dependent type <code>P</code> on <code>\ud835\udfd9+\ud835\udfd9</code> :</p> \\[ P := \\lambda_{x:1+1}, \\ \\text{match}(x,(\\lambda_{z:1}, 1),(\\lambda_{z:1}0)) \\] <p>I've mentioned this before but just another reminder, the 1s and 0s above are actually <code>\ud835\udfd9,\ud835\udfd8:Type</code>, KaTeX just won't render them for some reason</p> <p>Suppose we have a path <code>p:inl(\u22c6)=inr(\u22c6)</code>, then we use transport to obtain :</p> \\[ \\text{Transport}(\\text{inl}(\u22c6), \\text{inr}(\u22c6),p, P) : P(\\text{inl}(\u22c6))\u2192 P(\\text{inr}(\u22c6)) \\tag {5} \\] <p>According to the computation rules, we have</p> \\[ P(\\text{inl}(\u22c6)):= \\text{match}(\\text{inl}(\u22c6),(\u03bb_{z:1}, 1),(\\lambda_{z:1}, 0)) := [\u03bb_{z:1}, 1](\u22c6) := 1 \\] <p>and similarly <code>P(inr(\u22c6)):=\ud835\udfd8</code>. Thus, (5) is a function of type <code>\ud835\udfd9\u2192\ud835\udfd8</code>, and we can feed this function <code>\u22c6:\ud835\udfd9</code> to obtain a term of type <code>\ud835\udfd8</code>. All in all, we have infered a term of type <code>\ud835\udfd8</code> from the assumption of a path <code>p:inl(\u22c6)=inr(\u22c6)</code>, so we are done. If we want to be more complete, here is the complete proof term</p> \\[\\lambda_{p:\\text{inl}(\u22c6)=\\text{inr}(\u22c6)}, \\ \\left[\\text{Transport}(\\text{inl}(\u22c6), \\text{inr}(\u22c6),p, P)\\right](\u22c6) : (\\text{inl}(\u22c6)=\\text{inr}(\u22c6))\\to 0\\] <p>It is a huge problem if operations between propositions don't return propositions, but fortunately there is a solution to this problem which we will discuss in the next part.</p> <p>Let's not forget that since we also have</p> <p>if \\(P\\) is a predicate on \\(A\\) then \\(\u2200x\u2208A, P(x)\\) is a proposition</p> <p>We should also check that this statement holds in type theory as well, i.e, we should check that <code>P:A\u2192Prop</code> implies <code>\u220fx:A, P(x):Prop</code>. Of course we should also check this for \\(\\exists\\) too. </p>"},{"location":"Maths/Type%20Theory/part8/","title":"Part 8 - Propositional Truncation","text":"<p>Type Formation Rule</p> \\[\\frac{\\text{A}:\\text{Type}}{\\text{|A|}:\\text{Type}}\\] <p>For any type <code>A</code> we introduce the type <code>|A|</code>, called the propositional truncation of <code>A</code>. </p> <p>Term Introduction Rule</p> \\[\\frac{\\text{A}:\\text{Type}}{\\text{inc}:\\text{A}\\to\\text{|A|}}\\] <p>There is a function <code>inc:A\u2192|A|</code>, this ensures that we have: <code>|A|</code> is inhabited whenever <code>A</code> is </p> <p>because we can create an inhabitant of <code>|A|</code> by applying <code>inc</code> to an inhabitant of <code>A</code>. </p> <p>Observational Equality</p> \\[\\frac{a,b:\\text{|A|}}{p:a=b}\\] <p>Any two terms of the propositional truncation are equal. Obviously this means that <code>|A|:Prop</code> for any <code>A:Type</code>.</p> <p>Term Elimination Rule</p> \\[\\frac{\\text{A}:\\text{Type}, \\quad \\text{B}:\\text{Prop}, \\quad f:\\text{A}\\to\\text{B}}{g:\\text{|A|}\\to \\text{B}}\\] <p>A dependent version of the above rule exists, but is not particularly useful</p> <p>with the computation rule <code>g(|a|):=f(a)</code> for any <code>a:A</code>. The elimination rule basically means that when attempting to prove that a propositional truncation <code>|A|</code> implies a proposition <code>B</code>, then it suffices to prove (the often easier) <code>A</code> implies <code>B</code>. </p>"},{"location":"Maths/Type%20Theory/part8/#the-solution","title":"The solution","text":"<p>to our problem in the previous part is to apply a propositional truncation whenever an operation between two propositions <code>A,B:Prop</code> results in a type that isn't a proposition. </p> <p>The only troublesome operations to worry about is <code>+</code> and <code>\u2211</code>. Therefore, if we want to translate <code>A\u2228B</code> into type theory, we use <code>|A+B|</code> instead of the usual <code>A+B</code>. </p> <p>Again, <code>A\u2228B\u2192A+B</code> is not an incorrect translation, rather <code>A+B</code> is a constructive version of <code>A\u2228B</code>. If we are working under the context of intuitionistic logic, then the translation would in fact be accurate.</p> <p>Here is a full translation table given <code>P,Q:Prop</code> except the last two rows where <code>P:A\u2192Prop</code>.</p> <p></p>"},{"location":"Maths/Type%20Theory/part8/#differences","title":"Differences","text":"<p>To better understand propositional truncation, let us examine the differences between <code>\u2211x:A, P(x)</code> and <code>\u2203x:A, P(x)</code>.</p> <p>Surely <code>\u2211x:A, P(x) \u2192 A</code> is inhabited. <code>\u03c0\u2081</code> (from the elimination rule for dependent sum types) for example is an inhabitant of that type. This means that we can extract an inhabitant of <code>A</code> given a term of <code>\u2211x:A, P(x) \u2192 A</code>, we can then use that inhabitant of <code>A</code> in a proof argument later on. Would the same thing work for <code>\u2203x:A, P(x)</code>?</p> <p>According to the elimination rule, a function <code>g:\u2203x:A, P(x) \u2192 A</code> can be obtained from <code>\u03c0\u2081:\u2211x:A, P(x) \u2192 A</code>, but this is supposing that <code>A</code> is an h-proposition which is not always the case. What we can guarantee however is that <code>g:\u2203x:A, P(x) \u2192 |A|</code> is inhabited since we have <code>|A|:Prop</code> by definition. So we can extract an inhabitant of <code>|A|</code> instead of <code>A</code>. </p> <p>Whilst the judgement <code>a:A</code> demonstrates that <code>A</code> is inhabited, it also provides us access to a term of <code>A</code> that we can make use of. Meanwhile, the judgement <code>a:|A|</code> only has the benefit of demonstrating that <code>A</code> is inhabited.. and nothing else.</p> <p>You may imagine that it will be troublesome to work with <code>\u2203x:A, P(x)</code>. For example, one can imagine a situation where the next step of a proof requires proving <code>B:Type</code> whilst having an <code>f:A\u2192B</code> at hand. It is easy to do so starting from <code>q:\u2211x:A, P(x)</code> because <code>f(\u03c0\u2081(q)):B</code>. If instead we have <code>q:\u2203x:A, P(x)</code> then we can extract an <code>a:|A|</code> but we would be stuck since <code>a:|A|</code> can't be fed into <code>f:A\u2192B</code>. </p> <p>Trouble as it may be, most statements in (classical) mathematics can be represented as h-propositions. That is to say, if we encounter a similar situation (as described above), it will often be the case that <code>B:Prop</code>. Since that is the case, our <code>f:A\u2192B</code> can be converted to a <code>g:|A|\u2192B</code>, thus allowing us to proceed with the proof.</p> <p>Even then, having to take this additional step every single time is arduous. In Lean, there is an axiom should you wish to work under classical mathematics. It asserts that given any <code>A:Type</code> a function</p> <pre><code>classical.choice : |A| \u2192 A\n</code></pre> <p>exists. Although unnecessary, this basically allows us to sort of sweep under the rug the additional work and detail required when dealing with propositional truncations. In particular, we can treat <code>\u2203x:A, P(x)</code> as if it were (the more useful) <code>\u2211x:A, P(x)</code>. </p>"},{"location":"Maths/Type%20Theory/part8/#if-then-else-statments","title":"if-then-else statments","text":"<p>Now that we're more familiar with propositions, let us introduce a use case. Propositions, in particular the principle of LEM, allow us to model if-then-else statements in type theory. As a reminder, LEM asserts the existence of a function:</p> <pre><code>LEM : \u220fA:Prop, A + \u00acA\n</code></pre> <p>Given <code>A:Prop</code>, <code>B:Type</code>, <code>x:A\u2192B</code>, and <code>y:\u00acA\u2192B</code> we use the elimination rule for the sum type, <code>match</code>, to define:</p> <pre><code>dite A x y := match(LEM(A),x,y) : B\n</code></pre> <p>or if <code>x,y:B</code> then</p> <pre><code>ite A x y := match(LEM(A),[\u03bbp:A, x],[\u03bbp:\u00acA, y]) : B\n</code></pre> <p>Thus, <code>dite</code> can be thought of as the dependent version of <code>ite</code>. Let us showcase an example, suppose we want to show that</p> <pre><code>ite 1&lt;2 0 1 = 0\n</code></pre> <p>For simplicity's sake suppose we already have a proof <code>q:1&lt;2</code>, then <code>inl(q):1&lt;2 + \u00ac(1&lt;2)</code>, and according to the observational equality rule for propositions, we have the propositional equality <code>LEM(1&lt;2)=inl(q)</code>.</p> <p>By definition,</p> <pre><code>ite 1&lt;2 0 1 := match(LEM(1&lt;2), [\u03bbp:1&lt;2, 0], [\u03bbp:\u00ac1&lt;2, 1])\n</code></pre> <p>We can replace <code>LEM(1&lt;2)</code> with <code>inl(q)</code>, then the computation rule reduces the <code>match</code> expression to</p> <pre><code>[\u03bbp:1&lt;2, 0](q) := 0\n</code></pre> <p>If we had came up with a proof <code>q:\u00ac1&lt;2</code> instead it is easy to see that <code>ite 1&lt;2 0 1</code> will reduce to <code>1</code> instead of <code>0</code>. Hence, we can think of <code>ite 1&lt;2 0 1</code> as the statement:</p> <pre><code>if 1&lt;2 then 0 else 1\n</code></pre> <p><code>ite</code> is the if-then-else of the type theory universe (with <code>dite</code> being the dependent version).</p>"},{"location":"Maths/Type%20Theory/part9/","title":"A More Efficient Notation","text":"<p>As we move on to more complex concepts it is necessary to come up with a better notation system. The one I will use here bears a huge similarity to Lean's syntax. Before that, let's talk about pattern matching.</p>"},{"location":"Maths/Type%20Theory/part9/#pattern-matching","title":"Pattern Matching","text":"<p>is a way to define functions out of a <code>A:Type</code> with a case-by-case approach. Any term of <code>A:Type</code> will have to originate from its introduction rule, for example, if <code>n:\u2115</code> then we know that either <code>n=0</code> or <code>n=suc(m)</code> for some <code>m:\u2115</code>, and if <code>n:\ud835\udfd9</code> then the only possibility is <code>n=\u22c6</code>. </p> <p>For example, to define a function <code>f:\ud835\udfd9\u2192A</code> one only needs to specify a term of <code>A:Type</code> which <code>\u22c6:\ud835\udfd9</code> is supposed to be mapped to. To define a function <code>f:\u2115\u2192A</code> one needs to specify where <code>f</code> has to send <code>0:\u2115</code> and subsequently where <code>f</code> has to send <code>suc(n)</code>. This is precisely what the elimination rules for <code>\ud835\udfd9,\u2115:Type</code> accomplish, but we can make this more efficient.</p> <p>For instance, to define the addition function we can write</p> <pre><code>Def Add : \u2115 \u2192 \u2115 \u2192 \u2115\n| x 0 := x\n| x (suc y) := suc (add x y)\n</code></pre> <p>instead of defining it traditionally with <code>\u2115</code> elimination. Say we want to calculate <code>Add 1 3</code>, the computer will check if <code>1 3</code> suits the <code>x 0</code> pattern or the <code>x (suc y)</code> pattern. </p> <p>Since the computer views <code>3</code> as <code>suc suc suc 0</code>, the computer matches <code>1 3</code> with the <code>x (suc y)</code> pattern and it infers that <code>x=1</code> and <code>y=2</code>. Hence <code>Add 1 3 := suc (Add 1 2)</code>. One may of course perform the calculation again until no further progress can be made, giving the equality chain</p> <pre><code>Add 1 3 := suc (Add 1 2) \n        := suc suc (Add 1 1) \n        := suc suc suc (Add 1 0) \n        := suc suc suc 1\n        := suc suc suc suc 0 \n</code></pre> <pre><code>Def ite {B:Type} (A:Prop) (a,b:B) : B :=\nmatch LEM(A) with\n| inl _ := a\n| inr _ := b\n</code></pre> <pre><code>Def dite {B:Type} (A:Prop) (f:A\u2192B) (g:\u00acA\u2192B) : B :=\nmatch LEM(A) with\n| inl p := f p\n| inr q := g q\n</code></pre>"},{"location":"TIGM/","title":"Today in Good Music","text":"<p>Inspired by Mikasacus's tradition of sharing a piece of music he likes at the description of every uploaded video ---</p> <p>I will try (my best) to share and talk a bit about a piece of music that I find cool each day. This can be a single song or an entire albumn, I also listen to and enjoy most genres so you will find the catalouge to be quite diverse.</p> <p>Click HERE to view today's good music</p> <p>or use the archives below to navigate to a specific month.</p> <p>Obviously I won't be updating this daily (that's probably too much work), but I will try to be frequent.</p>"},{"location":"TIGM/#archives","title":"Archives","text":""},{"location":"TIGM/#2024","title":"2024","text":"<p>January &gt; February &gt; March &gt; April &gt; May &gt; June ...</p>"},{"location":"TIGM/#2023","title":"2023","text":"<p>July &gt; August &gt; September &gt; October &gt; November &gt; December</p>"},{"location":"TIGM/2023/August/","title":"August","text":""},{"location":"TIGM/2023/August/#17082023-vampillia-ft-jun-togawa-lilac","title":"17/08/2023: Vampillia (ft. Jun Togawa) \u22c5 lilac","text":"<p>Sorry for the long break, but I'll make it up with today's good music. An absolutely beautiful piece of music with a just as beautiful (albeit grim) piece of animation. There's not much information I can find on Vampillia, the band is really not that well known. They normally produce instrumental (apart from the screams lol) prog-rock, avant-garde type stuff, but they sometimes collab with singers to make vocal songs like in this case. </p> <p>Jun Togawa, the singer here, is an interesting character on her own and perhaps I will leave a discussion on her for a later time. The lyrics to this song are available but hard to find so I will leave a link here to it.</p>"},{"location":"TIGM/2023/December/","title":"December","text":""},{"location":"TIGM/2023/December/#24122023-the-sleepwalk-upon-a-brown","title":"24/12/2023: The Sleepwalk \u22c5 Upon A Brown","text":"<p>The Sleepwalk is a not so well known Japanese shoegaze band. It was hard to find information on this band, but thankfully a reddit post did the job for me. Right now there are 5 albums in total and although I haven't listened to all of them properly, this is my favorite so far.</p>"},{"location":"TIGM/2023/December/#24122023-1-trait-danger-sleds-for-christmas","title":"24/12/2023: 1 Trait Danger \u22c5 Sleds for Christmas","text":"<p>It's Christmas Eve! Have a Christmas song!</p>"},{"location":"TIGM/2023/December/#14122023-pinocchiop-non-breath-oblige","title":"14/12/2023: PINOCCHIOP \u22c5 Non-breath oblige","text":"<p>I refuse to believe that this song is humanly possible to sing. Especially that last part.. how is anyone supposed to do that. Yet.. yet, there are many covers of this song, I guess it just goes to show how talented these people are.</p> <p>ALSO, the music video is just so beautifully detailed and colorful. I like the watercolor aesthetic as well.</p>"},{"location":"TIGM/2023/December/#2122023-akiko-yano-water-ways-flow-backwards-again","title":"2/12/2023: Akiko Yano \u22c5 Water Ways Flow Backwards Again","text":"<p>A beautiful jazz piece by Akiko Yano, this rendition in particular is from her live album \"\u6771\u4eac\u306f\u591c\u306e7\u6642\" (Tokyo on a 7pm). Be sure to check out the other renditions (you can find them simply by searching the title on YouTube) because, as with jazz pieces, they vary greatly and are each their own experience.  </p> <p>Surprisingly, this piece is used as a sample in the rap song \"\u56de\u308b ft. RITTO &amp; \u7530\u6211\u6d41\" by KOJOE x Oliveoil. Personally, I don't think it gels well together but its cool to see the idea/attempt.</p>"},{"location":"TIGM/2023/July/","title":"July","text":""},{"location":"TIGM/2023/July/#30072023-homeland-hanggai","title":"30/07/2023: Homeland \u22c5 Hanggai","text":"<p>I've come across this just a couple days ago so I have not had time to properly listen to it yet, but oh my.. am I absolutely in love with this already. How could you not!? It's Mongolian folk-rock! Don't tell me that doesn't sound the slightest bit interesting.</p> <p>Homeland (\u6545\u4e61) is the 7th studio album by Hanngai (\u676d\u76d6). So far, I am really digging the first (\u5587\u561b\u5927\u53d4\u63a2\u4eb2\u8bb0) and seventh (\u6c5f\u683c\u5c14) songs. The titles are all in Chinese (probably to make it more readable/recognizable to the general audience), but the songs are mostly sung in Mongolian. The band heavily resonates with their Mongolian background, they incorporate traditional instruments such as the morin khuur and topshur as well as Mongolian throat singing (a famous example), which is often combined with west-modern styles and instruments as well.</p> <p>The main audience seems to be of western origin, which is a shame since the band's main intention is to rekindle interest towards Mongolian culture within China. This is because most Mongols migrate to China and other more developed nations, and therefore do not get to experience their culture (see here).</p>"},{"location":"TIGM/2023/July/#26072023-the-same-things-happening-to-me-all-the-time-even-in-my-dreams-teen-suicide","title":"26/07/2023: the same things happening to me all the time, even in my dreams \u22c5 Teen Suicide","text":"<p>A sad song with lyrics that hit hard. The title especially, although very long, reflects how most people with depression tend to have a hard time waking up and spend most of their time asleep to avoid having to experience life. Often times however, sorrows from life do seep into dreams, making escape even more difficult. The song exudes total hopelessness, just as in the above scenario.</p> <p>The band also goes by American Pleasure Club.</p>"},{"location":"TIGM/2023/July/#25072023-late-night-delivery-doctor-pizza","title":"25/07/2023: Late Night Delivery \u22c5 Doctor Pizza","text":"<p>Late Night Delivery is a modern jazz-funk album by doctor pizza. The beginning piano solo on Cosmic Carpet Ride in particular is very entrancing. It is quite similar to the piano segment of JVKE's Golden Hour, and I found it surprising how a similar piano melody can be incorporated into a very different genre.</p>"},{"location":"TIGM/2023/July/#16072023-alto-glide-alan-hawkshaw","title":"16/07/2023: Alto Glide \u22c5 Alan Hawkshaw","text":"<p>One of the tracks from the jazz-funk library music album \"KPM 1000 series : Synthesis\". KPM is a literal treasure trove for chill-sounding background music like these and many others. It was produced by Alan Hawkshaw (and possibly Brian Bennett) sometime around 1974. </p> <p>Library music like these are often popular among music makers, amateurs and pro alike, for use as sampling material. For an overview, click here</p>"},{"location":"TIGM/2023/July/#11072023-crepuscolo-sul-mare-piero-umiliani","title":"11/07/2023: Crepuscolo sul mare \u22c5 Piero Umiliani","text":"<p>The title is in Italian and translates into \"Dusk on the sea\". It is a soundtrack made for the 1969 Italian thriller film La legge dei gangsters. Piero Umiliani - being an Italian composer for film scores - composed music for many other films during the 1960s and 1970s. </p> <p>This track in particular has seeped its way back into the modern age; being featured in the 2004 film \"Ocean's 12\" and also sampled by Lil Yachty in the song \"Concrete Goonies\" and by Jon McxRo in the song \"Somewhere in Italy\".</p>"},{"location":"TIGM/2023/July/#09072023-amethyst-choker-sped-up-thorhighheels","title":"09/07/2023: Amethyst Choker [sped up] \u22c5 ThorHighHeels","text":"<p>A track from the YouTuber ThorHighHeels. I haven't watched his content yet, but it seems like he makes videos talking about weird and obscure video games (which I find interesting, so I may give it a watch at some point). Other than that, he makes EDM style music (as you can tell). </p> <p>He also composes the music for several video games, most notably Producer 2021 and Umurangi Generation. Both of them look interesting at first glance so I may play them at some point. </p>"},{"location":"TIGM/2023/July/#07072023-red-sun-in-the-sky","title":"07/07/2023: Red Sun in the Sky \u22c5 \u5c60\u6d2a\u521a","text":"<p>Why is this so good? and why can't I stop bopping to it? </p> <p>Warning. This was difficult to research because information relating to it is hard to find and also in a different language. Take it with a grain of salt.</p> <p>This song comes from an album titled \"\u7ea2\u592a\u9633\u2014\u2014\u6bdb\u6cfd\u4e1c\u9882\u6b4c\u65b0\u8282\u594f\u8054\u5531\" which consists of modernized versions of older classics (most of them idolizing Mao Zedong). This is a massive album consisting of 5 CDs; each CD consisting of 30 songs to give a grand total of 150 songs. Each song in the album also seamlessly transistions into the next; this probably makes it the longest 'seamless transition' album.</p> <p>You can listen to all 5 CDs on YouTube.  Alternatively, high quality downloads can be found here. </p> <p>The video linked above has amassed over 27M views at the time of writing, the popularity came as a result of it being the subject of various memes and edits. The song in the video seems to be a slightly faster and higher pitched version mashing together the 2nd (\u5929\u4e0a\u592a\u9633\u7ea2\u5f64\u5f64) and 24th (\u5ef6\u8fb9\u4eba\u6c11\u70ed\u7231\u6bdb\u4e3b\u5e2d) song from the first CD. </p> <p>Also see the album titled \"\u6b4c\u5531\u6bdb\u6cfd\u4e1c \u7fa4\u661f\u9882\u4f1f\u4eba\" where you can find alternative versions of the songs.</p>"},{"location":"TIGM/2023/July/#06072023-lower-ones-eyes-nuyuri","title":"06/07/2023: Lower One's Eyes \u22c5 Nuyuri","text":"<p>This was the song that got me into the vocaloid rabbit hole. I have listened to many other vocaloids since, but this still remains one of my favorites. It has hints of jazz and maybe ragtime which I find really cool (I love genre hybrids), this is probably more apparent when listening to the piano covers.</p> <p>I first discovered this vocaloid song through an OMORI animatic which utilized the same music (OMORI is an awesome game). Not only that but this animatic managed to capture the style and sequences perfectly from the original vocaloid MV. It is truly a well produced animatic which is why I decided to share this part as well.</p> <p>It turns out there is a whole trend of appropriating vocaloid MVs into other fandoms. For example inputting <code>\u624b\u63cf\u304dOMORI</code> as a search string in YouTube will provide you with a whole list.</p> <p>\"\\(\\small \\stackrel{\\tiny \u3066}{\u624b}\\stackrel{\\tiny \u304c}{\u63cf}\u304d\\)\" (or alternatively \\(\\small \\stackrel{\\tiny \u3066}{\u624b}\\stackrel{\\tiny \u304c}{\u66f8}\u304d\\)) translates to handwriting (according to Jisho) and is to be used as a noun. However I find it is more frequently used to refer to something that is hand-drawn, hand-painted, or specifically in this case a hand-drawn (not in a literal sense but with a drawing tablet) animation.</p> <p>\u3082\u3061\u308d\u3093 this means you can type <code>\u624b\u63cf\u304d[INSERT_FANDOM]</code> into a search engine and find some cool animations relating to a particular fandom from Japanese creators.  </p>"},{"location":"TIGM/2023/November/","title":"November","text":""},{"location":"TIGM/2023/November/#23112023-maurice-ravel-le-tombeau-de-couperin","title":"23/11/2023: Maurice Ravel \u22c5 Le Tombeau de Couperin","text":"<p>Maurice Ravel was a French composer. The title \"Le Tombeau de Couperin\" translates to \"the grave of Couperin\". While tombeau means tomb in French, it was also a popular term (in the 17th century) to refer to a musical composition that is in memory of someone's death. Here, Couperin is thought to be Fran\u00e7ois Couperin, a French Baroque composer from the 17th century (the Couperin family is itself a musical family, much of the members are famous composers as well). However, Ravel did not write this piece in memory of Couperin, but instead in memory of his friends that died in WW1 while he served in the army. The piece does incorporate Barqoue elements, which is why Couperin's name shows up.</p> <p>The piece is divided into six parts: Pr\u00e9lude: 0:00, Fugue: 3:02, Forlane: 6:02, Rigaudon: 12:11, Menuet: 15:17, Toccata: 20:16. With each part corresponding to specific people (my favorite is prelude).</p>"},{"location":"TIGM/2023/November/#11112023-frederic-chopin-etude-op-25-no-5","title":"11/11/2023: Fr\u00e9d\u00e9ric Chopin \u22c5 \u00c9tude Op. 25, No. 5","text":"<p>This piece is also often nicknamed \"Wrong Note\", the reason for it is apparent once you start listening to the song (and if you have a bit of a musical ear). Chopin intentionally plays the \"wrong note\", creating a dissonance, a phenomenon where the sounds of two notes sort of clash and don't sound nice together. Chopin however quickly switches back to playing the correct note, making things sound nice again. He repeats this pattern for the first part of the song, and for those of you that can read sheet music you can see this in action below:</p> <p></p> <p>This etude, and many other classical songs, were made popular by the anime \"Your lie in April\" \u22c5 \u56db\u6708\u306f\u541b\u306e\u5618. The video above in particular is a performance of \"Wrong Note\" from the anime's soundtrack: \u201d\u56db\u6708\u306f\u541b\u306e\u5618\u3000\u50d5\u3068\u541b\u3068\u306e\u97f3\u697d\u5e33\u201d. I played the piano as a kid and that was what got me into watching this anime and exploring more about classical music. There are many more interesting pieces I've run into as a result, which I'll try to post here at some point. </p>"},{"location":"TIGM/2023/October/","title":"October","text":""},{"location":"TIGM/2023/October/#29102023-bbng-charlotte-day-wilson-sleeper","title":"29/10/2023: BBNG &amp; Charlotte Day Wilson \u22c5 Sleeper","text":"<p>Bad Bad Not Good (BBNG) is an instrumental jazz hip-hop band, but they do frequently collaborate with singers/rappers to produce songs with vocals. </p> <p>Up here is their most recent example (at the time of writing) in collaboration with Charlotte Day Wilson. She has also appeared in the song \"In Your Eyes\" from BBNG's album, IV. At the same time, BBNG has appeared in \"I Can Only Whisper\" from her debut album, Alpha. </p>"},{"location":"TIGM/2023/October/#15102023-pharoah-sanders-kazuko","title":"15/10/2023: Pharoah Sanders \u22c5 Kazuko","text":"<p>I don't know what it is with people using Japanese in their music titles, but I'm all for it... I mean, it gives me more to talk about over here, but first! Pharoah Sanders was a brilliant saxophonist (the part at 4:13 gives me chills), he sadly passed away quite recently (September 2022). </p> <p>The footage here comes from a 2007 DVD \"Pharoah Sanders - Live in San Fransisco\", but it was recorded during July of 1982 at an abandoned tunnel somewhere in the Marin Headlands. They performed the song Kazuko (from Sanders' \"Journey to the One\" album).</p> <p>The guy next to him is Paul Arslanian playing the harmonium. </p> <p>Now for the Japanese. The kanji for \"Kazuko\" is \u548c\u5b50 and it is used as a feminine Japanese name. It is composed of \u548c (wa) meaning peace - as in the word \u5e73\u548c (heiwa) - and \u5b50 (ko) meaning child. Thus, Kazuko has the implied meaning \"Peace Child\", which is the alternative name this song is sometimes referred by.   </p> <p>The album version of Kazuko is quite different from this one. Notably it uses the japanese instrument, koto, for the background. </p>"},{"location":"TIGM/2023/September/","title":"September","text":""},{"location":"TIGM/2023/September/#14092023-machine-girl","title":"14/09/2023: Machine Girl \u22c5 \u3046\u305a\u307e\u304d","text":"<p>\u3046\u305a\u307e\u304d is pronounced \"uzumaki\" and translates to whirlpool from Japanese. It is unclear why Machine Girl chose to give this song that name, I have tried scouring the internet to no avail. Some people have pointed out that \u3046\u305a\u307e\u304d could refer to the horror manga series by the famous Junji Ito.</p> <p>I will link a video by FUNke talking about Junji Ito. It's very well produced!</p> <p>The connection to Junji Ito is not far-fetched since the band's name comes from a 2008 Japanese movie, The Machine Girl. But onto the music itself we go.. it is very chaotic with many moving parts, overwhelming but at the same time mesmerizing. I like that there are short calm segments of the music sprinkled in between the screaming, one of these segments in particular (1:39-1:49) is quite popular, more so than the actual song itself probably. </p> <p>This is because it was quite a popular trend at some point to make edits/animations based on this segment, see this for example. There are also people who have extended this segment to a full song. </p> <p>This segment is actually a sample from the Sonic CD video game soundtrack: Palmtree Panic \"P\" mix.</p> <p>I also want to share this Chainsaw Man edit which uses \u3046\u305a\u307e\u304d, because it is just SO COOL.</p>"},{"location":"TIGM/2023/September/#04092023-willy-rodriguez-bad-therapists","title":"04/09/2023: Willy Rodriguez \u22c5 Bad Therapists","text":"<p>I'm back! Let's just ignore that August has only one song in it. I was busy moving places and while looking for some new music to listen to while packing I came across Willy Rodriguez. </p> <p>I was first drawn because the art style is similar to (in fact, inspired by) Car Seat Headrest's Twin Fantasy album cover AND I LOVE CAR SEAT HEADREST. </p> <p></p> <p>You may also notice that this is also where I got my YouTube character from. </p> <p>The similarity is only in the artstyle, the music itself is quite different. It is more pop than rock, but both have lo-fi aspects. Anyways, I like their music and I listened to it on repeat while preparing to move. This EP in particular is my favorite so far.</p> <p>I should also mention that Willy Rodriguez is a project by two people, William and Star. They also go by WillyRodriguezWasTaken, because, well, Willy Rodiguez was already taken by someone else.</p>"},{"location":"TIGM/2024/April/","title":"April","text":""},{"location":"TIGM/2024/April/#29042024-balming-tiger-sos","title":"29/04/2024: Balming Tiger \u22c5 SOS","text":"<p>Balming Tiger has quickly become one of my favorite bands. Each of their music is unique and not defined by a single genre/theme. Their music videos are also unique, especially in terms of cinematography. Take for instance at 0:34 where the camera moves in for a close-up and then continues moving past, switching to a reverse shot. Or at 3:25 with the rotating zoom-in whose effect continues past what we presumed to be the object of focus (the man in the car). And OMG you have to check their official website too, its so cool to play around with.</p> <p>I don't know cinematography terms that well, so I might be using these terms inaccurately.  </p>"},{"location":"TIGM/2024/April/#22042024-alice-schach-and-the-magic-orchestra-killed-by-angel","title":"22/04/2024: Alice Schach and the Magic Orchestra \u22c5 KILLED BY ANGEL","text":"<p>This band is pretty unique in that all their songs feature their own constructed language (conlang) known as \"Alician\". There are official translations to the song lyrics, thus making it possible to decode this language; several people have undertaken this task. I initially thought that this seemed like a ridiculous (I mean that in a positive way) idea, but it turns out that songs sung in fictitious language are not a rare occurrence.</p>"},{"location":"TIGM/2024/February/","title":"February","text":""},{"location":"TIGM/2024/February/#20022024-sion-comedy","title":"20/02/2024: Sion \u22c5 Comedy","text":"<p>Sion is Korean but was born and raised in Germany and only just recently moved back to Korea. Before officially making music, he participated in The Voice Germany, reaching the semi-finals.</p> <p>He's gotten a lot better since then. Here is a live performance with a good collection of songs if you want more of his voice.</p>"},{"location":"TIGM/2024/February/#15022024-esperanto-danse-macabre","title":"15/02/2024: Esperanto \u22c5 Danse Macabre","text":"<p>Esperanto is a prog rock band. The song I chose to highlight from them is a prog rock cover of a classical composition, Danse Macabre, by Camille Saint-Sa\u00ebns. I just thought that it was an interesting idea, and I quite liked the cover as well.</p> <p>Esperanto also happens to be the name of the most widely spoken and successfull constructed language (conlang). Whether this naming choice is intentional or has no real meaning is unapparent.</p>"},{"location":"TIGM/2024/January/","title":"January","text":""},{"location":"TIGM/2024/January/#26012024-the-smile-bending-hectic","title":"26/01/2024: The Smile \u22c5 Bending Hectic","text":"<p>The Smile is a quite recently formed Radiohead spinoff band. \"Bending Hectic\" is a song from their second album \"Wall of Eyes\", released just TODAY (26/01/2024). \"Bending Hectic\" itself was released as a single much earlier on. </p> <p>I haven't listened to the album yet, but I'm sure it will be a banger considering how good \"Bending Hectic\" is.</p>"},{"location":"TIGM/2024/January/#18012024-joe-valence-brae-punk-tactics","title":"18/01/2024: Joe Valence &amp; Brae \u22c5 PUNK TACTICS","text":"<p>This was made when!?</p>"},{"location":"TIGM/2024/January/#08012024-joni-mitchell-coyote","title":"08/01/2024: Joni Mitchell \u22c5 Coyote","text":"<p>This comes from her 8th studio album, Hejira, which apparently was mostly written in a car during a cross-country road trip from Maine to California. To reflect this, the title of the album comes from the Arabic word \u0627\u0644\u0647\u062c\u0631\u0629 (hijrah) which refers to the journey prophet Muhammad took from Mecca to Medina. Anyway, I think the origin story of this album is pretty cool, and the songs, especially coyote, also cool.</p>"},{"location":"TIGM/2024/June/","title":"June","text":"<p>It's pride month, so I will feature LGBT-themed songs for this month</p>"},{"location":"TIGM/2024/June/#18062024-kevin-abstract-empty","title":"18/06/2024: Kevin Abstract \u22c5 Empty","text":"<p>This is the opener to Kevin Abstract's album, American Boyfriend. The music video also includes I Do (End Credits), the last song of the album, for.. well the end credits of the music video. This song was recommended to me by a friend. Although I do listen to BROCKHAMPTON (a rap band led by Kevin), I haven't had the chance to listen to Kevin's individual projects/music until recently and his stuff has been a pleasure to dive into so I'm glad for this recommendation.</p>"},{"location":"TIGM/2024/March/","title":"March","text":""},{"location":"TIGM/2024/March/#25032024-na-chinese-nostalgia","title":"25/03/2024: [N/A] \u22c5 Chinese Nostalgia","text":"<p>I randomly came across a chinese song which sounded familiar from my childhood, then went on a rabbithole to find other similar songs. The end result is the playlist you see above. These are the songs I'd hear in the background when we went to restaurants with family or family friends, when we went to weddings, during chinese new year celebrations, and also from the CDs and cassettes my grandma would play when she was driving.</p>"},{"location":"TIGM/2024/May/","title":"May","text":""},{"location":"TIGM/2024/May/#28052024-christopher-larkin-hollow-knight-piano-collections","title":"28/05/2024: Christopher Larkin \u22c5 Hollow Knight Piano Collections","text":"<p>An actual daily update!? (when was the last time that happened?). These are piano versions of the Hollow Knight original soundtrack (my all-time favorite game). The OST (which is more orchestral in nature) was composed by Christopher Larkin, but the piano compositions are from David Peacock and Augustine Mayuga Gonzales who are also involved with making music for other famous indie video games like Hyper Light Drifter, Ori and the Blind Forest, etc...</p> <p>I used to be able to play White Palace, Sealed Vessel, and Radiance on piano (not as elegantly as is here ofc), but that was like 5-6 years ago. I haven't touched the piano since so it was kinda sad listening to these pieces coz it's like \"man.. I used to be able to play this.. and now I can't\" </p> <p>There is also a \"Piano Collections\" for Undertale; also by David Peacock and Augustine Mayuga Gonzales.</p>"},{"location":"TIGM/2024/May/#27052024-pharoah-sanders-harvest-time","title":"27/05/2024: Pharoah Sanders \u22c5 Harvest Time","text":"<p>This is the first time an artist has appeared twice on TIGM!! It's Pharaoh Sanders again. This time I'm showcasing the 20 minute long \"Harvest Time\" from his 1977 self-titled album. The album was reissued in 2023, now including two live performances of \"Harvest Time\" and you can hear them here (though they sound very different from the studio version).</p>"},{"location":"TIGM/2024/May/#08052024-sloche-stadacone","title":"08/05/2024: Sloche \u22c5 Stadacon\u00e9","text":"<p>Sloche was a prog rock band formed in Quebec during the 1970s. Not much is known about them. They've only released two albums and this is the first song from the second. It's kinda sad to see bands just fade away into obscurity due to lack of popularity. Even if they do somehow become relevant many years later, it is ultimately too late. </p>"},{"location":"TIGM/2024/May/#04052024-kendrick-lamar-euphoria","title":"04/05/2024: Kendrick Lamar \u22c5 Euphoria","text":"<p>Now, I have no context about what the beef is between Kendrick and Drake, but I'm just happy we are getting a bunch of sick diss tracks as a result. Euphoria by Kendrick is my favorite out of the several diss tracks thats been released so far. I like Kendrick's music in general, he's one of my favorites and is a very brilliant lyricist.</p> <p>Timeline :</p> <p>First Person Shooter (Drake) -&gt; Like That (Kendrick) -&gt; Push Ups, Taylor Made (Drake) -&gt; Euphoria 6:16 in L.A (Kendrick) -&gt; Family Matters (Drake) -&gt; Meet the Grahams, Not Like Us (Kendrick)</p>"}]}